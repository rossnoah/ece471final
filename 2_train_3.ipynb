{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42efbf30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 21600\n",
      "test size: 5400\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "MODEL_NUMBER = 3\n",
    "\n",
    "    \n",
    "# seed so random stuff isnt random\n",
    "SEED = 100\n",
    "\n",
    "# transforms\n",
    "transform = transforms.Compose([\n",
    "\n",
    "    transforms.RandomResizedCrop(64, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "dataset = torchvision.datasets.EuroSAT(root='./data', download=True, transform=transform)\n",
    "\n",
    "# split into train, test\n",
    "# 80% train, 20% test \n",
    "train_ratio = 0.8\n",
    "test_ratio = 0.2\n",
    "\n",
    "\n",
    "total_size = len(dataset)\n",
    "train_size = int(total_size * train_ratio)\n",
    "test_size = total_size - train_size\n",
    "\n",
    "\n",
    "train_dataset, test_dataset = random_split(\n",
    "    dataset, [train_size, test_size],\n",
    "    generator=torch.Generator().manual_seed(SEED)\n",
    ")\n",
    "\n",
    "print(f\"train: {len(train_dataset)}\")\n",
    "print(f\"test size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa92cd06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Model(\n",
      "  (relu): ReLU()\n",
      "  (c1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (c2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout1): Dropout2d(p=0.25, inplace=False)\n",
      "  (c3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout2): Dropout2d(p=0.25, inplace=False)\n",
      "  (maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=2048, out_features=64, bias=True)\n",
      "  (dropout3): Dropout(p=0.5, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n",
      "Total parameters: 137818\n"
     ]
    }
   ],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "        self.c1 = torch.nn.Conv2d(3, 8, 3, padding=1)\n",
    "        self.c2 = torch.nn.Conv2d(8, 16, 3, padding=1)\n",
    "        self.maxpool1 = torch.nn.MaxPool2d(2)\n",
    "        self.dropout1 = torch.nn.Dropout2d(0.25)\n",
    "        self.c3 = torch.nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.maxpool2 = torch.nn.MaxPool2d(2)\n",
    "        self.dropout2 = torch.nn.Dropout2d(0.25)\n",
    "        self.maxpool3 = torch.nn.MaxPool2d(2)\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.fc1 = torch.nn.Linear(32 * 8 * 8, 64)\n",
    "        self.dropout3 = torch.nn.Dropout(0.5)\n",
    "        self.fc2 = torch.nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.c1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.c2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.c3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.maxpool3(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = Model()\n",
    "print(f\"Model: {model}\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "499a7ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# dataloaders\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=128, \n",
    "    shuffle=True,\n",
    "    pin_memory=True, # for use on gpu\n",
    "    num_workers=4 # arbitrarily chosen. some sources recommend 4 per gpu\n",
    ")\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=128, \n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b139e4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "if device == \"cuda\":\n",
    "    model.to(device, non_blocking=True) # according to pytorch docs we can do this if memory is pinned\n",
    "else:  \n",
    "    model.to(device)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "205d254c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch():\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def test_one_epoch():\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa66e8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "train loss: 1.9316 | test acc: 26.25%\n",
      "test loss:  1.5886 | test acc:  41.54%\n",
      "\n",
      "Epoch 2/100\n",
      "train loss: 1.5982 | test acc: 37.58%\n",
      "test loss:  1.3929 | test acc:  46.24%\n",
      "\n",
      "Epoch 3/100\n",
      "train loss: 1.4798 | test acc: 42.84%\n",
      "test loss:  1.3037 | test acc:  52.80%\n",
      "\n",
      "Epoch 4/100\n",
      "train loss: 1.4054 | test acc: 46.52%\n",
      "test loss:  1.2476 | test acc:  55.44%\n",
      "\n",
      "Epoch 5/100\n",
      "train loss: 1.3544 | test acc: 49.79%\n",
      "test loss:  1.1724 | test acc:  58.76%\n",
      "\n",
      "Epoch 6/100\n",
      "train loss: 1.3112 | test acc: 51.58%\n",
      "test loss:  1.1617 | test acc:  58.13%\n",
      "\n",
      "Epoch 7/100\n",
      "train loss: 1.2744 | test acc: 53.47%\n",
      "test loss:  1.0863 | test acc:  62.04%\n",
      "\n",
      "Epoch 8/100\n",
      "train loss: 1.2412 | test acc: 54.55%\n",
      "test loss:  1.0670 | test acc:  62.28%\n",
      "\n",
      "Epoch 9/100\n",
      "train loss: 1.2061 | test acc: 56.03%\n",
      "test loss:  0.9946 | test acc:  65.30%\n",
      "\n",
      "Epoch 10/100\n",
      "train loss: 1.1791 | test acc: 57.70%\n",
      "test loss:  0.9823 | test acc:  64.50%\n",
      "\n",
      "Epoch 11/100\n",
      "train loss: 1.1531 | test acc: 58.54%\n",
      "test loss:  0.9518 | test acc:  65.22%\n",
      "\n",
      "Epoch 12/100\n",
      "train loss: 1.1300 | test acc: 59.32%\n",
      "test loss:  0.9514 | test acc:  66.65%\n",
      "\n",
      "Epoch 13/100\n",
      "train loss: 1.1313 | test acc: 59.20%\n",
      "test loss:  0.9343 | test acc:  67.26%\n",
      "\n",
      "Epoch 14/100\n",
      "train loss: 1.0949 | test acc: 60.70%\n",
      "test loss:  0.9095 | test acc:  67.89%\n",
      "\n",
      "Epoch 15/100\n",
      "train loss: 1.0957 | test acc: 60.60%\n",
      "test loss:  0.9009 | test acc:  67.54%\n",
      "\n",
      "Epoch 16/100\n",
      "train loss: 1.0862 | test acc: 61.09%\n",
      "test loss:  0.8878 | test acc:  68.59%\n",
      "\n",
      "Epoch 17/100\n",
      "train loss: 1.0598 | test acc: 62.09%\n",
      "test loss:  0.8582 | test acc:  69.50%\n",
      "\n",
      "Epoch 18/100\n",
      "train loss: 1.0547 | test acc: 62.04%\n",
      "test loss:  0.8702 | test acc:  68.50%\n",
      "\n",
      "Epoch 19/100\n",
      "train loss: 1.0507 | test acc: 62.42%\n",
      "test loss:  0.8582 | test acc:  68.78%\n",
      "\n",
      "Epoch 20/100\n",
      "train loss: 1.0465 | test acc: 62.55%\n",
      "test loss:  0.8464 | test acc:  69.72%\n",
      "checkpoint saved: checkpoints/train_3_20251119_112315/model_epoch_20.pt\n",
      "\n",
      "Epoch 21/100\n",
      "train loss: 1.0264 | test acc: 63.29%\n",
      "test loss:  0.8311 | test acc:  69.81%\n",
      "\n",
      "Epoch 22/100\n",
      "train loss: 1.0114 | test acc: 63.94%\n",
      "test loss:  0.8252 | test acc:  70.44%\n",
      "\n",
      "Epoch 23/100\n",
      "train loss: 1.0170 | test acc: 63.67%\n",
      "test loss:  0.8466 | test acc:  70.00%\n",
      "\n",
      "Epoch 24/100\n",
      "train loss: 0.9957 | test acc: 64.05%\n",
      "test loss:  0.8187 | test acc:  70.72%\n",
      "\n",
      "Epoch 25/100\n",
      "train loss: 0.9845 | test acc: 64.55%\n",
      "test loss:  0.8129 | test acc:  69.80%\n",
      "\n",
      "Epoch 26/100\n",
      "train loss: 0.9777 | test acc: 65.02%\n",
      "test loss:  0.7922 | test acc:  71.33%\n",
      "\n",
      "Epoch 27/100\n",
      "train loss: 0.9852 | test acc: 64.94%\n",
      "test loss:  0.8050 | test acc:  71.43%\n",
      "\n",
      "Epoch 28/100\n",
      "train loss: 0.9652 | test acc: 65.50%\n",
      "test loss:  0.7702 | test acc:  72.74%\n",
      "\n",
      "Epoch 29/100\n",
      "train loss: 0.9664 | test acc: 65.29%\n",
      "test loss:  0.7861 | test acc:  71.81%\n",
      "\n",
      "Epoch 30/100\n",
      "train loss: 0.9617 | test acc: 65.89%\n",
      "test loss:  0.7928 | test acc:  71.85%\n",
      "\n",
      "Epoch 31/100\n",
      "train loss: 0.9610 | test acc: 65.94%\n",
      "test loss:  0.7635 | test acc:  72.65%\n",
      "\n",
      "Epoch 32/100\n",
      "train loss: 0.9355 | test acc: 66.88%\n",
      "test loss:  0.7691 | test acc:  71.91%\n",
      "\n",
      "Epoch 33/100\n",
      "train loss: 0.9506 | test acc: 65.80%\n",
      "test loss:  0.7623 | test acc:  73.80%\n",
      "\n",
      "Epoch 34/100\n",
      "train loss: 0.9334 | test acc: 66.72%\n",
      "test loss:  0.7566 | test acc:  72.63%\n",
      "\n",
      "Epoch 35/100\n",
      "train loss: 0.9328 | test acc: 66.66%\n",
      "test loss:  0.7274 | test acc:  74.37%\n",
      "\n",
      "Epoch 36/100\n",
      "train loss: 0.9324 | test acc: 67.15%\n",
      "test loss:  0.7297 | test acc:  74.39%\n",
      "\n",
      "Epoch 37/100\n",
      "train loss: 0.9197 | test acc: 67.43%\n",
      "test loss:  0.7279 | test acc:  74.31%\n",
      "\n",
      "Epoch 38/100\n",
      "train loss: 0.9140 | test acc: 67.43%\n",
      "test loss:  0.7222 | test acc:  74.83%\n",
      "\n",
      "Epoch 39/100\n",
      "train loss: 0.9118 | test acc: 67.45%\n",
      "test loss:  0.7418 | test acc:  72.76%\n",
      "\n",
      "Epoch 40/100\n",
      "train loss: 0.9076 | test acc: 67.99%\n",
      "test loss:  0.7044 | test acc:  74.94%\n",
      "checkpoint saved: checkpoints/train_3_20251119_112315/model_epoch_40.pt\n",
      "\n",
      "Epoch 41/100\n",
      "train loss: 0.9069 | test acc: 68.02%\n",
      "test loss:  0.7193 | test acc:  74.11%\n",
      "\n",
      "Epoch 42/100\n",
      "train loss: 0.9022 | test acc: 67.66%\n",
      "test loss:  0.7193 | test acc:  74.41%\n",
      "\n",
      "Epoch 43/100\n",
      "train loss: 0.8928 | test acc: 68.46%\n",
      "test loss:  0.7081 | test acc:  74.76%\n",
      "\n",
      "Epoch 44/100\n",
      "train loss: 0.8866 | test acc: 68.50%\n",
      "test loss:  0.7225 | test acc:  74.37%\n",
      "\n",
      "Epoch 45/100\n",
      "train loss: 0.8861 | test acc: 68.75%\n",
      "test loss:  0.6745 | test acc:  76.67%\n",
      "\n",
      "Epoch 46/100\n",
      "train loss: 0.8801 | test acc: 68.35%\n",
      "test loss:  0.7022 | test acc:  75.15%\n",
      "\n",
      "Epoch 47/100\n",
      "train loss: 0.8781 | test acc: 69.21%\n",
      "test loss:  0.6988 | test acc:  75.28%\n",
      "\n",
      "Epoch 48/100\n",
      "train loss: 0.8834 | test acc: 68.70%\n",
      "test loss:  0.6699 | test acc:  77.07%\n",
      "\n",
      "Epoch 49/100\n",
      "train loss: 0.8779 | test acc: 69.20%\n",
      "test loss:  0.6822 | test acc:  76.67%\n",
      "\n",
      "Epoch 50/100\n",
      "train loss: 0.8673 | test acc: 69.12%\n",
      "test loss:  0.6906 | test acc:  75.50%\n",
      "\n",
      "Epoch 51/100\n",
      "train loss: 0.8739 | test acc: 69.35%\n",
      "test loss:  0.6795 | test acc:  76.17%\n",
      "\n",
      "Epoch 52/100\n",
      "train loss: 0.8568 | test acc: 69.98%\n",
      "test loss:  0.6788 | test acc:  76.22%\n",
      "\n",
      "Epoch 53/100\n",
      "train loss: 0.8708 | test acc: 69.62%\n",
      "test loss:  0.6860 | test acc:  76.22%\n",
      "\n",
      "Epoch 54/100\n",
      "train loss: 0.8555 | test acc: 69.89%\n",
      "test loss:  0.6935 | test acc:  75.72%\n",
      "\n",
      "Epoch 55/100\n",
      "train loss: 0.8566 | test acc: 70.27%\n",
      "test loss:  0.6553 | test acc:  77.26%\n",
      "\n",
      "Epoch 56/100\n",
      "train loss: 0.8473 | test acc: 70.34%\n",
      "test loss:  0.6804 | test acc:  76.65%\n",
      "\n",
      "Epoch 57/100\n",
      "train loss: 0.8615 | test acc: 69.62%\n",
      "test loss:  0.6759 | test acc:  76.56%\n",
      "\n",
      "Epoch 58/100\n",
      "train loss: 0.8497 | test acc: 70.31%\n",
      "test loss:  0.6569 | test acc:  77.00%\n",
      "\n",
      "Epoch 59/100\n",
      "train loss: 0.8531 | test acc: 70.33%\n",
      "test loss:  0.6581 | test acc:  77.37%\n",
      "\n",
      "Epoch 60/100\n",
      "train loss: 0.8476 | test acc: 70.01%\n",
      "test loss:  0.6529 | test acc:  77.13%\n",
      "checkpoint saved: checkpoints/train_3_20251119_112315/model_epoch_60.pt\n",
      "\n",
      "Epoch 61/100\n",
      "train loss: 0.8376 | test acc: 70.92%\n",
      "test loss:  0.6333 | test acc:  77.76%\n",
      "\n",
      "Epoch 62/100\n",
      "train loss: 0.8353 | test acc: 70.63%\n",
      "test loss:  0.6303 | test acc:  77.83%\n",
      "\n",
      "Epoch 63/100\n",
      "train loss: 0.8334 | test acc: 70.89%\n",
      "test loss:  0.6776 | test acc:  76.43%\n",
      "\n",
      "Epoch 64/100\n",
      "train loss: 0.8353 | test acc: 71.19%\n",
      "test loss:  0.6512 | test acc:  76.96%\n",
      "\n",
      "Epoch 65/100\n",
      "train loss: 0.8330 | test acc: 70.75%\n",
      "test loss:  0.6368 | test acc:  78.17%\n",
      "\n",
      "Epoch 66/100\n",
      "train loss: 0.8325 | test acc: 70.88%\n",
      "test loss:  0.6600 | test acc:  76.20%\n",
      "\n",
      "Epoch 67/100\n",
      "train loss: 0.8322 | test acc: 70.69%\n",
      "test loss:  0.6592 | test acc:  76.72%\n",
      "\n",
      "Epoch 68/100\n",
      "train loss: 0.8233 | test acc: 71.25%\n",
      "test loss:  0.6267 | test acc:  78.70%\n",
      "\n",
      "Epoch 69/100\n",
      "train loss: 0.8218 | test acc: 71.40%\n",
      "test loss:  0.6245 | test acc:  78.13%\n",
      "\n",
      "Epoch 70/100\n",
      "train loss: 0.8210 | test acc: 71.07%\n",
      "test loss:  0.6426 | test acc:  77.43%\n",
      "\n",
      "Epoch 71/100\n",
      "train loss: 0.8230 | test acc: 71.44%\n",
      "test loss:  0.6288 | test acc:  77.78%\n",
      "\n",
      "Epoch 72/100\n",
      "train loss: 0.8306 | test acc: 70.99%\n",
      "test loss:  0.6430 | test acc:  78.04%\n",
      "\n",
      "Epoch 73/100\n",
      "train loss: 0.8144 | test acc: 71.59%\n",
      "test loss:  0.6244 | test acc:  78.28%\n",
      "\n",
      "Epoch 74/100\n",
      "train loss: 0.8136 | test acc: 71.28%\n",
      "test loss:  0.6318 | test acc:  78.06%\n",
      "\n",
      "Epoch 75/100\n",
      "train loss: 0.8125 | test acc: 71.78%\n",
      "test loss:  0.6056 | test acc:  79.52%\n",
      "\n",
      "Epoch 76/100\n",
      "train loss: 0.8104 | test acc: 71.51%\n",
      "test loss:  0.6336 | test acc:  78.43%\n",
      "\n",
      "Epoch 77/100\n",
      "train loss: 0.8207 | test acc: 71.50%\n",
      "test loss:  0.6435 | test acc:  77.72%\n",
      "\n",
      "Epoch 78/100\n",
      "train loss: 0.8191 | test acc: 71.33%\n",
      "test loss:  0.6193 | test acc:  78.87%\n",
      "\n",
      "Epoch 79/100\n",
      "train loss: 0.8008 | test acc: 71.65%\n",
      "test loss:  0.6205 | test acc:  78.15%\n",
      "\n",
      "Epoch 80/100\n",
      "train loss: 0.8086 | test acc: 71.55%\n",
      "test loss:  0.6239 | test acc:  78.70%\n",
      "checkpoint saved: checkpoints/train_3_20251119_112315/model_epoch_80.pt\n",
      "\n",
      "Epoch 81/100\n",
      "train loss: 0.8087 | test acc: 71.95%\n",
      "test loss:  0.5942 | test acc:  79.69%\n",
      "\n",
      "Epoch 82/100\n",
      "train loss: 0.7921 | test acc: 72.27%\n",
      "test loss:  0.6103 | test acc:  78.69%\n",
      "\n",
      "Epoch 83/100\n",
      "train loss: 0.8042 | test acc: 72.18%\n",
      "test loss:  0.6349 | test acc:  78.24%\n",
      "\n",
      "Epoch 84/100\n",
      "train loss: 0.7939 | test acc: 71.94%\n",
      "test loss:  0.6098 | test acc:  78.76%\n",
      "\n",
      "Epoch 85/100\n",
      "train loss: 0.8026 | test acc: 72.13%\n",
      "test loss:  0.6082 | test acc:  79.17%\n",
      "\n",
      "Epoch 86/100\n",
      "train loss: 0.7985 | test acc: 72.25%\n",
      "test loss:  0.6121 | test acc:  78.67%\n",
      "\n",
      "Epoch 87/100\n",
      "train loss: 0.7925 | test acc: 72.93%\n",
      "test loss:  0.5976 | test acc:  79.26%\n",
      "\n",
      "Epoch 88/100\n",
      "train loss: 0.7974 | test acc: 72.16%\n",
      "test loss:  0.5940 | test acc:  79.24%\n",
      "\n",
      "Epoch 89/100\n",
      "train loss: 0.8017 | test acc: 72.23%\n",
      "test loss:  0.6050 | test acc:  78.72%\n",
      "\n",
      "Epoch 90/100\n",
      "train loss: 0.8006 | test acc: 72.24%\n",
      "test loss:  0.5989 | test acc:  79.30%\n",
      "\n",
      "Epoch 91/100\n",
      "train loss: 0.7893 | test acc: 72.77%\n",
      "test loss:  0.6059 | test acc:  79.28%\n",
      "\n",
      "Epoch 92/100\n",
      "train loss: 0.7797 | test acc: 72.80%\n",
      "test loss:  0.6143 | test acc:  78.02%\n",
      "\n",
      "Epoch 93/100\n",
      "train loss: 0.7956 | test acc: 72.47%\n",
      "test loss:  0.5986 | test acc:  79.31%\n",
      "\n",
      "Epoch 94/100\n",
      "train loss: 0.7838 | test acc: 72.84%\n",
      "test loss:  0.6056 | test acc:  78.80%\n",
      "\n",
      "Epoch 95/100\n",
      "train loss: 0.7854 | test acc: 72.67%\n",
      "test loss:  0.5896 | test acc:  79.89%\n",
      "\n",
      "Epoch 96/100\n",
      "train loss: 0.7823 | test acc: 72.86%\n",
      "test loss:  0.6134 | test acc:  78.50%\n",
      "\n",
      "Epoch 97/100\n",
      "train loss: 0.7784 | test acc: 72.92%\n",
      "test loss:  0.6005 | test acc:  79.00%\n",
      "\n",
      "Epoch 98/100\n",
      "train loss: 0.7793 | test acc: 72.95%\n",
      "test loss:  0.6054 | test acc:  78.41%\n",
      "\n",
      "Epoch 99/100\n",
      "train loss: 0.7767 | test acc: 73.12%\n",
      "test loss:  0.5703 | test acc:  80.33%\n",
      "\n",
      "Epoch 100/100\n",
      "train loss: 0.7621 | test acc: 73.02%\n",
      "test loss:  0.5752 | test acc:  80.15%\n",
      "checkpoint saved: checkpoints/train_3_20251119_112315/model_epoch_100.pt\n",
      "\n",
      "final checkpoint saved: checkpoints/train_3_20251119_112315/model_final.pt\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "# tensorboard setup\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/train_{}_{}'.format(MODEL_NUMBER, timestamp))\n",
    "\n",
    "checkpoint_dir = f'checkpoints/train_{MODEL_NUMBER}_{timestamp}'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "    \n",
    "\n",
    "\n",
    "    train_loss, train_acc = train_one_epoch()\n",
    "    \n",
    "    test_loss, test_acc = test_one_epoch()\n",
    "    \n",
    "    print(f'train loss: {train_loss:.4f} | test acc: {train_acc:.2f}%')\n",
    "    print(f'test loss:  {test_loss:.4f} | test acc:  {test_acc:.2f}%')\n",
    "    \n",
    "    # log data\n",
    "    writer.add_scalar('loss/1_train', train_loss, epoch + 1)\n",
    "    writer.add_scalar('loss/2_test', test_loss, epoch + 1)\n",
    "    writer.add_scalar('accuracy/1_train', train_acc, epoch + 1)\n",
    "    writer.add_scalar('accuracy/2_test', test_acc, epoch + 1)\n",
    "    writer.flush()\n",
    "    \n",
    "    # checkpoint every 20 epochs\n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'model_epoch_{epoch + 1}.pt')\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "        print(f'checkpoint saved: {checkpoint_path}')\n",
    "    \n",
    "    print()\n",
    "\n",
    "# save final model\n",
    "final_checkpoint_path = os.path.join(checkpoint_dir, f'model_final.pt')\n",
    "torch.save(model.state_dict(), final_checkpoint_path)\n",
    "print(f'final checkpoint saved: {final_checkpoint_path}')\n",
    "\n",
    "writer.close()\n",
    "print('Complete')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
