{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42efbf30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 21600\n",
      "test size: 5400\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "MODEL_NUMBER = 5\n",
    "\n",
    "    \n",
    "# seed so random stuff isnt random\n",
    "SEED = 100\n",
    "\n",
    "# transforms\n",
    "transform = transforms.Compose([\n",
    "\n",
    "    transforms.RandomResizedCrop(64, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "dataset = torchvision.datasets.EuroSAT(root='./data', download=True, transform=transform)\n",
    "\n",
    "# split into train, test\n",
    "# 80% train, 20% test \n",
    "train_ratio = 0.8\n",
    "test_ratio = 0.2\n",
    "\n",
    "\n",
    "total_size = len(dataset)\n",
    "train_size = int(total_size * train_ratio)\n",
    "test_size = total_size - train_size\n",
    "\n",
    "\n",
    "train_dataset, test_dataset = random_split(\n",
    "    dataset, [train_size, test_size],\n",
    "    generator=torch.Generator().manual_seed(SEED)\n",
    ")\n",
    "\n",
    "print(f\"train: {len(train_dataset)}\")\n",
    "print(f\"test size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa92cd06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: ResNet-18 (no pretrained weights)\n",
      "Total parameters: 11181642\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "# resnet 18 model\n",
    "model = models.resnet18(weights=None)\n",
    "\n",
    "\n",
    "# classifier head with 10 outputs\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = torch.nn.Linear(num_ftrs, 10)\n",
    "\n",
    "print(f\"Model: ResNet-18 (no pretrained weights)\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "499a7ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# dataloaders\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=128, \n",
    "    shuffle=True,\n",
    "    pin_memory=True, # for use on gpu\n",
    "    num_workers=4 # arbitrarily chosen. some sources recommend 4 per gpu\n",
    ")\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=128, \n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b139e4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "if device == \"cuda\":\n",
    "    model.to(device, non_blocking=True) # according to pytorch docs we can do this if memory is pinned\n",
    "else:  \n",
    "    model.to(device)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "205d254c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch():\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def test_one_epoch():\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa66e8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "train loss: 1.1723 | train acc: 56.91%\n",
      "test loss:  2.1007 | test acc:  37.00%\n",
      "\n",
      "Epoch 2/200\n",
      "train loss: 0.9142 | train acc: 66.61%\n",
      "test loss:  4.0525 | test acc:  29.70%\n",
      "\n",
      "Epoch 3/200\n",
      "train loss: 0.7958 | train acc: 71.39%\n",
      "test loss:  1.9774 | test acc:  40.98%\n",
      "\n",
      "Epoch 4/200\n",
      "train loss: 0.7113 | train acc: 74.82%\n",
      "test loss:  3.1684 | test acc:  33.50%\n",
      "\n",
      "Epoch 5/200\n",
      "train loss: 0.6283 | train acc: 77.60%\n",
      "test loss:  1.0770 | test acc:  62.06%\n",
      "\n",
      "Epoch 6/200\n",
      "train loss: 0.5594 | train acc: 80.14%\n",
      "test loss:  0.8743 | test acc:  68.11%\n",
      "\n",
      "Epoch 7/200\n",
      "train loss: 0.5066 | train acc: 82.13%\n",
      "test loss:  1.4217 | test acc:  52.80%\n",
      "\n",
      "Epoch 8/200\n",
      "train loss: 0.4901 | train acc: 82.48%\n",
      "test loss:  0.8937 | test acc:  70.28%\n",
      "\n",
      "Epoch 9/200\n",
      "train loss: 0.4267 | train acc: 85.28%\n",
      "test loss:  1.8681 | test acc:  58.37%\n",
      "\n",
      "Epoch 10/200\n",
      "train loss: 0.4156 | train acc: 85.34%\n",
      "test loss:  0.7403 | test acc:  74.19%\n",
      "\n",
      "Epoch 11/200\n",
      "train loss: 0.3901 | train acc: 86.19%\n",
      "test loss:  1.1543 | test acc:  63.54%\n",
      "\n",
      "Epoch 12/200\n",
      "train loss: 0.3630 | train acc: 87.24%\n",
      "test loss:  0.6586 | test acc:  77.19%\n",
      "\n",
      "Epoch 13/200\n",
      "train loss: 0.3328 | train acc: 88.19%\n",
      "test loss:  0.7891 | test acc:  74.07%\n",
      "\n",
      "Epoch 14/200\n",
      "train loss: 0.3305 | train acc: 88.49%\n",
      "test loss:  0.6099 | test acc:  78.50%\n",
      "\n",
      "Epoch 15/200\n",
      "train loss: 0.3095 | train acc: 89.14%\n",
      "test loss:  0.6952 | test acc:  79.80%\n",
      "\n",
      "Epoch 16/200\n",
      "train loss: 0.3054 | train acc: 89.11%\n",
      "test loss:  0.4144 | test acc:  85.56%\n",
      "\n",
      "Epoch 17/200\n",
      "train loss: 0.2971 | train acc: 89.61%\n",
      "test loss:  0.4912 | test acc:  82.80%\n",
      "\n",
      "Epoch 18/200\n",
      "train loss: 0.2746 | train acc: 90.36%\n",
      "test loss:  0.4730 | test acc:  84.33%\n",
      "\n",
      "Epoch 19/200\n",
      "train loss: 0.2731 | train acc: 90.24%\n",
      "test loss:  0.5612 | test acc:  81.50%\n",
      "\n",
      "Epoch 20/200\n",
      "train loss: 0.2690 | train acc: 90.60%\n",
      "test loss:  1.3065 | test acc:  66.74%\n",
      "checkpoint saved: checkpoints/train_5_20251119_220510/model_epoch_20.pt\n",
      "\n",
      "Epoch 21/200\n",
      "train loss: 0.2561 | train acc: 90.99%\n",
      "test loss:  0.5547 | test acc:  81.81%\n",
      "\n",
      "Epoch 22/200\n",
      "train loss: 0.2459 | train acc: 91.40%\n",
      "test loss:  0.3376 | test acc:  88.57%\n",
      "\n",
      "Epoch 23/200\n",
      "train loss: 0.2367 | train acc: 91.64%\n",
      "test loss:  0.5978 | test acc:  79.48%\n",
      "\n",
      "Epoch 24/200\n",
      "train loss: 0.2349 | train acc: 91.50%\n",
      "test loss:  1.4984 | test acc:  63.02%\n",
      "\n",
      "Epoch 25/200\n",
      "train loss: 0.2138 | train acc: 92.31%\n",
      "test loss:  0.6013 | test acc:  81.35%\n",
      "\n",
      "Epoch 26/200\n",
      "train loss: 0.2178 | train acc: 92.27%\n",
      "test loss:  2.9062 | test acc:  53.59%\n",
      "\n",
      "Epoch 27/200\n",
      "train loss: 0.2127 | train acc: 92.39%\n",
      "test loss:  0.5864 | test acc:  80.94%\n",
      "\n",
      "Epoch 28/200\n",
      "train loss: 0.2140 | train acc: 92.44%\n",
      "test loss:  0.4097 | test acc:  86.43%\n",
      "\n",
      "Epoch 29/200\n",
      "train loss: 0.1941 | train acc: 93.06%\n",
      "test loss:  0.8103 | test acc:  76.70%\n",
      "\n",
      "Epoch 30/200\n",
      "train loss: 0.1932 | train acc: 93.12%\n",
      "test loss:  0.6282 | test acc:  80.44%\n",
      "\n",
      "Epoch 31/200\n",
      "train loss: 0.1969 | train acc: 93.20%\n",
      "test loss:  0.7418 | test acc:  79.09%\n",
      "\n",
      "Epoch 32/200\n",
      "train loss: 0.1817 | train acc: 93.68%\n",
      "test loss:  0.8943 | test acc:  74.04%\n",
      "\n",
      "Epoch 33/200\n",
      "train loss: 0.1801 | train acc: 93.60%\n",
      "test loss:  0.3626 | test acc:  87.80%\n",
      "\n",
      "Epoch 34/200\n",
      "train loss: 0.1851 | train acc: 93.62%\n",
      "test loss:  0.5214 | test acc:  83.85%\n",
      "\n",
      "Epoch 35/200\n",
      "train loss: 0.1731 | train acc: 93.68%\n",
      "test loss:  1.5244 | test acc:  66.24%\n",
      "\n",
      "Epoch 36/200\n",
      "train loss: 0.1728 | train acc: 93.92%\n",
      "test loss:  0.9404 | test acc:  76.63%\n",
      "\n",
      "Epoch 37/200\n",
      "train loss: 0.1606 | train acc: 94.28%\n",
      "test loss:  0.3700 | test acc:  88.30%\n",
      "\n",
      "Epoch 38/200\n",
      "train loss: 0.1570 | train acc: 94.31%\n",
      "test loss:  0.2818 | test acc:  90.31%\n",
      "\n",
      "Epoch 39/200\n",
      "train loss: 0.1566 | train acc: 94.39%\n",
      "test loss:  0.4295 | test acc:  85.98%\n",
      "\n",
      "Epoch 40/200\n",
      "train loss: 0.1589 | train acc: 94.43%\n",
      "test loss:  1.0873 | test acc:  72.56%\n",
      "checkpoint saved: checkpoints/train_5_20251119_220510/model_epoch_40.pt\n",
      "\n",
      "Epoch 41/200\n",
      "train loss: 0.1510 | train acc: 94.88%\n",
      "test loss:  0.5220 | test acc:  84.09%\n",
      "\n",
      "Epoch 42/200\n",
      "train loss: 0.1446 | train acc: 95.06%\n",
      "test loss:  0.8012 | test acc:  76.56%\n",
      "\n",
      "Epoch 43/200\n",
      "train loss: 0.1409 | train acc: 95.00%\n",
      "test loss:  0.2511 | test acc:  91.70%\n",
      "\n",
      "Epoch 44/200\n",
      "train loss: 0.1466 | train acc: 94.63%\n",
      "test loss:  1.7541 | test acc:  63.74%\n",
      "\n",
      "Epoch 45/200\n",
      "train loss: 0.1352 | train acc: 95.28%\n",
      "test loss:  0.5446 | test acc:  84.70%\n",
      "\n",
      "Epoch 46/200\n",
      "train loss: 0.1361 | train acc: 95.19%\n",
      "test loss:  0.8992 | test acc:  74.70%\n",
      "\n",
      "Epoch 47/200\n",
      "train loss: 0.1358 | train acc: 95.10%\n",
      "test loss:  0.7703 | test acc:  77.48%\n",
      "\n",
      "Epoch 48/200\n",
      "train loss: 0.1323 | train acc: 95.32%\n",
      "test loss:  0.6504 | test acc:  83.04%\n",
      "\n",
      "Epoch 49/200\n",
      "train loss: 0.1276 | train acc: 95.49%\n",
      "test loss:  0.3743 | test acc:  87.72%\n",
      "\n",
      "Epoch 50/200\n",
      "train loss: 0.1248 | train acc: 95.57%\n",
      "test loss:  0.4293 | test acc:  86.26%\n",
      "\n",
      "Epoch 51/200\n",
      "train loss: 0.1249 | train acc: 95.51%\n",
      "test loss:  0.4935 | test acc:  85.15%\n",
      "\n",
      "Epoch 52/200\n",
      "train loss: 0.1257 | train acc: 95.52%\n",
      "test loss:  0.5449 | test acc:  83.72%\n",
      "\n",
      "Epoch 53/200\n",
      "train loss: 0.1180 | train acc: 95.72%\n",
      "test loss:  0.6075 | test acc:  82.39%\n",
      "\n",
      "Epoch 54/200\n",
      "train loss: 0.1215 | train acc: 95.92%\n",
      "test loss:  0.5858 | test acc:  82.24%\n",
      "\n",
      "Epoch 55/200\n",
      "train loss: 0.1094 | train acc: 96.12%\n",
      "test loss:  0.4571 | test acc:  86.31%\n",
      "\n",
      "Epoch 56/200\n",
      "train loss: 0.1057 | train acc: 96.19%\n",
      "test loss:  0.4816 | test acc:  85.57%\n",
      "\n",
      "Epoch 57/200\n",
      "train loss: 0.1089 | train acc: 96.12%\n",
      "test loss:  0.5663 | test acc:  83.59%\n",
      "\n",
      "Epoch 58/200\n",
      "train loss: 0.1176 | train acc: 95.76%\n",
      "test loss:  0.5299 | test acc:  84.96%\n",
      "\n",
      "Epoch 59/200\n",
      "train loss: 0.1132 | train acc: 96.02%\n",
      "test loss:  0.3534 | test acc:  88.63%\n",
      "\n",
      "Epoch 60/200\n",
      "train loss: 0.1025 | train acc: 96.38%\n",
      "test loss:  0.6918 | test acc:  81.15%\n",
      "checkpoint saved: checkpoints/train_5_20251119_220510/model_epoch_60.pt\n",
      "\n",
      "Epoch 61/200\n",
      "train loss: 0.0974 | train acc: 96.45%\n",
      "test loss:  0.3191 | test acc:  90.15%\n",
      "\n",
      "Epoch 62/200\n",
      "train loss: 0.1030 | train acc: 96.32%\n",
      "test loss:  0.3964 | test acc:  88.26%\n",
      "\n",
      "Epoch 63/200\n",
      "train loss: 0.0988 | train acc: 96.56%\n",
      "test loss:  0.6970 | test acc:  82.94%\n",
      "\n",
      "Epoch 64/200\n",
      "train loss: 0.1044 | train acc: 96.31%\n",
      "test loss:  0.4240 | test acc:  87.80%\n",
      "\n",
      "Epoch 65/200\n",
      "train loss: 0.0897 | train acc: 96.71%\n",
      "test loss:  0.4852 | test acc:  85.57%\n",
      "\n",
      "Epoch 66/200\n",
      "train loss: 0.0975 | train acc: 96.52%\n",
      "test loss:  0.6810 | test acc:  81.85%\n",
      "\n",
      "Epoch 67/200\n",
      "train loss: 0.0872 | train acc: 96.94%\n",
      "test loss:  1.4921 | test acc:  71.37%\n",
      "\n",
      "Epoch 68/200\n",
      "train loss: 0.0884 | train acc: 96.96%\n",
      "test loss:  0.3795 | test acc:  88.91%\n",
      "\n",
      "Epoch 69/200\n",
      "train loss: 0.0808 | train acc: 97.22%\n",
      "test loss:  0.3642 | test acc:  89.20%\n",
      "\n",
      "Epoch 70/200\n",
      "train loss: 0.0901 | train acc: 96.81%\n",
      "test loss:  0.4174 | test acc:  88.81%\n",
      "\n",
      "Epoch 71/200\n",
      "train loss: 0.0795 | train acc: 97.22%\n",
      "test loss:  0.7140 | test acc:  81.72%\n",
      "\n",
      "Epoch 72/200\n",
      "train loss: 0.0889 | train acc: 97.03%\n",
      "test loss:  0.5170 | test acc:  86.26%\n",
      "\n",
      "Epoch 73/200\n",
      "train loss: 0.0797 | train acc: 97.16%\n",
      "test loss:  0.5371 | test acc:  85.22%\n",
      "\n",
      "Epoch 74/200\n",
      "train loss: 0.0759 | train acc: 97.27%\n",
      "test loss:  0.3901 | test acc:  89.72%\n",
      "\n",
      "Epoch 75/200\n",
      "train loss: 0.0823 | train acc: 97.12%\n",
      "test loss:  2.0212 | test acc:  65.43%\n",
      "\n",
      "Epoch 76/200\n",
      "train loss: 0.0777 | train acc: 97.16%\n",
      "test loss:  2.8959 | test acc:  62.98%\n",
      "\n",
      "Epoch 77/200\n",
      "train loss: 0.0711 | train acc: 97.48%\n",
      "test loss:  0.2969 | test acc:  91.26%\n",
      "\n",
      "Epoch 78/200\n",
      "train loss: 0.0878 | train acc: 96.86%\n",
      "test loss:  0.3893 | test acc:  89.15%\n",
      "\n",
      "Epoch 79/200\n",
      "train loss: 0.0793 | train acc: 97.38%\n",
      "test loss:  0.3975 | test acc:  89.02%\n",
      "\n",
      "Epoch 80/200\n",
      "train loss: 0.0774 | train acc: 97.29%\n",
      "test loss:  0.6340 | test acc:  83.56%\n",
      "checkpoint saved: checkpoints/train_5_20251119_220510/model_epoch_80.pt\n",
      "\n",
      "Epoch 81/200\n",
      "train loss: 0.0739 | train acc: 97.44%\n",
      "test loss:  0.4028 | test acc:  89.15%\n",
      "\n",
      "Epoch 82/200\n",
      "train loss: 0.0691 | train acc: 97.48%\n",
      "test loss:  1.0471 | test acc:  74.43%\n",
      "\n",
      "Epoch 83/200\n",
      "train loss: 0.0747 | train acc: 97.42%\n",
      "test loss:  0.3769 | test acc:  89.06%\n",
      "\n",
      "Epoch 84/200\n",
      "train loss: 0.0657 | train acc: 97.70%\n",
      "test loss:  0.8690 | test acc:  81.39%\n",
      "\n",
      "Epoch 85/200\n",
      "train loss: 0.0679 | train acc: 97.73%\n",
      "test loss:  0.3070 | test acc:  90.78%\n",
      "\n",
      "Epoch 86/200\n",
      "train loss: 0.0682 | train acc: 97.69%\n",
      "test loss:  0.3961 | test acc:  89.17%\n",
      "\n",
      "Epoch 87/200\n",
      "train loss: 0.0661 | train acc: 97.69%\n",
      "test loss:  0.4229 | test acc:  88.41%\n",
      "\n",
      "Epoch 88/200\n",
      "train loss: 0.0687 | train acc: 97.60%\n",
      "test loss:  0.6565 | test acc:  83.56%\n",
      "\n",
      "Epoch 89/200\n",
      "train loss: 0.0661 | train acc: 97.63%\n",
      "test loss:  0.4375 | test acc:  89.24%\n",
      "\n",
      "Epoch 90/200\n",
      "train loss: 0.0660 | train acc: 97.63%\n",
      "test loss:  0.5365 | test acc:  86.52%\n",
      "\n",
      "Epoch 91/200\n",
      "train loss: 0.0702 | train acc: 97.60%\n",
      "test loss:  0.3995 | test acc:  89.20%\n",
      "\n",
      "Epoch 92/200\n",
      "train loss: 0.0617 | train acc: 97.88%\n",
      "test loss:  0.2866 | test acc:  91.56%\n",
      "\n",
      "Epoch 93/200\n",
      "train loss: 0.0631 | train acc: 97.83%\n",
      "test loss:  0.5312 | test acc:  85.26%\n",
      "\n",
      "Epoch 94/200\n",
      "train loss: 0.0626 | train acc: 97.72%\n",
      "test loss:  0.4735 | test acc:  87.43%\n",
      "\n",
      "Epoch 95/200\n",
      "train loss: 0.0587 | train acc: 98.00%\n",
      "test loss:  0.6073 | test acc:  85.02%\n",
      "\n",
      "Epoch 96/200\n",
      "train loss: 0.0539 | train acc: 98.12%\n",
      "test loss:  0.4511 | test acc:  88.61%\n",
      "\n",
      "Epoch 97/200\n",
      "train loss: 0.0688 | train acc: 97.50%\n",
      "test loss:  0.3486 | test acc:  90.17%\n",
      "\n",
      "Epoch 98/200\n",
      "train loss: 0.0611 | train acc: 97.79%\n",
      "test loss:  0.4172 | test acc:  89.44%\n",
      "\n",
      "Epoch 99/200\n",
      "train loss: 0.0610 | train acc: 97.97%\n",
      "test loss:  1.5979 | test acc:  70.17%\n",
      "\n",
      "Epoch 100/200\n",
      "train loss: 0.0516 | train acc: 98.14%\n",
      "test loss:  0.3361 | test acc:  90.72%\n",
      "checkpoint saved: checkpoints/train_5_20251119_220510/model_epoch_100.pt\n",
      "\n",
      "Epoch 101/200\n",
      "train loss: 0.0528 | train acc: 98.16%\n",
      "test loss:  0.7145 | test acc:  87.48%\n",
      "\n",
      "Epoch 102/200\n",
      "train loss: 0.0541 | train acc: 98.12%\n",
      "test loss:  0.3794 | test acc:  90.15%\n",
      "\n",
      "Epoch 103/200\n",
      "train loss: 0.0567 | train acc: 98.05%\n",
      "test loss:  0.3267 | test acc:  91.20%\n",
      "\n",
      "Epoch 104/200\n",
      "train loss: 0.0551 | train acc: 98.06%\n",
      "test loss:  0.3521 | test acc:  90.70%\n",
      "\n",
      "Epoch 105/200\n",
      "train loss: 0.0571 | train acc: 98.02%\n",
      "test loss:  0.6375 | test acc:  82.26%\n",
      "\n",
      "Epoch 106/200\n",
      "train loss: 0.0557 | train acc: 98.11%\n",
      "test loss:  0.8653 | test acc:  81.15%\n",
      "\n",
      "Epoch 107/200\n",
      "train loss: 0.0536 | train acc: 98.16%\n",
      "test loss:  0.3447 | test acc:  91.26%\n",
      "\n",
      "Epoch 108/200\n",
      "train loss: 0.0523 | train acc: 98.19%\n",
      "test loss:  0.4312 | test acc:  88.61%\n",
      "\n",
      "Epoch 109/200\n",
      "train loss: 0.0524 | train acc: 98.08%\n",
      "test loss:  0.3636 | test acc:  90.19%\n",
      "\n",
      "Epoch 110/200\n",
      "train loss: 0.0541 | train acc: 98.15%\n",
      "test loss:  0.3407 | test acc:  90.91%\n",
      "\n",
      "Epoch 111/200\n",
      "train loss: 0.0504 | train acc: 98.25%\n",
      "test loss:  0.4338 | test acc:  88.30%\n",
      "\n",
      "Epoch 112/200\n",
      "train loss: 0.0530 | train acc: 98.09%\n",
      "test loss:  0.3403 | test acc:  89.89%\n",
      "\n",
      "Epoch 113/200\n",
      "train loss: 0.0546 | train acc: 98.15%\n",
      "test loss:  0.5124 | test acc:  87.39%\n",
      "\n",
      "Epoch 114/200\n",
      "train loss: 0.0488 | train acc: 98.38%\n",
      "test loss:  0.5034 | test acc:  88.39%\n",
      "\n",
      "Epoch 115/200\n",
      "train loss: 0.0476 | train acc: 98.38%\n",
      "test loss:  0.5394 | test acc:  86.65%\n",
      "\n",
      "Epoch 116/200\n",
      "train loss: 0.0505 | train acc: 98.23%\n",
      "test loss:  0.3594 | test acc:  90.96%\n",
      "\n",
      "Epoch 117/200\n",
      "train loss: 0.0444 | train acc: 98.41%\n",
      "test loss:  2.0475 | test acc:  65.94%\n",
      "\n",
      "Epoch 118/200\n",
      "train loss: 0.0502 | train acc: 98.26%\n",
      "test loss:  0.3382 | test acc:  91.04%\n",
      "\n",
      "Epoch 119/200\n",
      "train loss: 0.0645 | train acc: 97.99%\n",
      "test loss:  0.3075 | test acc:  91.44%\n",
      "\n",
      "Epoch 120/200\n",
      "train loss: 0.0430 | train acc: 98.50%\n",
      "test loss:  0.7929 | test acc:  82.13%\n",
      "checkpoint saved: checkpoints/train_5_20251119_220510/model_epoch_120.pt\n",
      "\n",
      "Epoch 121/200\n",
      "train loss: 0.0448 | train acc: 98.53%\n",
      "test loss:  0.3683 | test acc:  89.94%\n",
      "\n",
      "Epoch 122/200\n",
      "train loss: 0.0418 | train acc: 98.54%\n",
      "test loss:  0.3651 | test acc:  91.24%\n",
      "\n",
      "Epoch 123/200\n",
      "train loss: 0.0444 | train acc: 98.47%\n",
      "test loss:  0.3230 | test acc:  91.57%\n",
      "\n",
      "Epoch 124/200\n",
      "train loss: 0.0440 | train acc: 98.46%\n",
      "test loss:  0.5604 | test acc:  87.07%\n",
      "\n",
      "Epoch 125/200\n",
      "train loss: 0.0488 | train acc: 98.42%\n",
      "test loss:  0.3092 | test acc:  91.57%\n",
      "\n",
      "Epoch 126/200\n",
      "train loss: 0.0409 | train acc: 98.62%\n",
      "test loss:  0.3185 | test acc:  91.33%\n",
      "\n",
      "Epoch 127/200\n",
      "train loss: 0.0475 | train acc: 98.27%\n",
      "test loss:  0.4329 | test acc:  89.61%\n",
      "\n",
      "Epoch 128/200\n",
      "train loss: 0.0458 | train acc: 98.39%\n",
      "test loss:  0.3873 | test acc:  90.65%\n",
      "\n",
      "Epoch 129/200\n",
      "train loss: 0.0419 | train acc: 98.53%\n",
      "test loss:  2.1878 | test acc:  67.72%\n",
      "\n",
      "Epoch 130/200\n",
      "train loss: 0.0439 | train acc: 98.52%\n",
      "test loss:  0.2477 | test acc:  93.15%\n",
      "\n",
      "Epoch 131/200\n",
      "train loss: 0.0372 | train acc: 98.65%\n",
      "test loss:  0.4444 | test acc:  88.69%\n",
      "\n",
      "Epoch 132/200\n",
      "train loss: 0.0402 | train acc: 98.64%\n",
      "test loss:  0.3886 | test acc:  90.52%\n",
      "\n",
      "Epoch 133/200\n",
      "train loss: 0.0468 | train acc: 98.35%\n",
      "test loss:  0.5136 | test acc:  87.41%\n",
      "\n",
      "Epoch 134/200\n",
      "train loss: 0.0425 | train acc: 98.46%\n",
      "test loss:  0.3064 | test acc:  92.26%\n",
      "\n",
      "Epoch 135/200\n",
      "train loss: 0.0364 | train acc: 98.75%\n",
      "test loss:  0.3511 | test acc:  90.56%\n",
      "\n",
      "Epoch 136/200\n",
      "train loss: 0.0449 | train acc: 98.47%\n",
      "test loss:  0.3316 | test acc:  92.33%\n",
      "\n",
      "Epoch 137/200\n",
      "train loss: 0.0371 | train acc: 98.62%\n",
      "test loss:  0.6785 | test acc:  84.59%\n",
      "\n",
      "Epoch 138/200\n",
      "train loss: 0.0419 | train acc: 98.52%\n",
      "test loss:  0.6159 | test acc:  85.80%\n",
      "\n",
      "Epoch 139/200\n",
      "train loss: 0.0425 | train acc: 98.58%\n",
      "test loss:  0.3621 | test acc:  90.59%\n",
      "\n",
      "Epoch 140/200\n",
      "train loss: 0.0353 | train acc: 98.85%\n",
      "test loss:  0.4015 | test acc:  90.57%\n",
      "checkpoint saved: checkpoints/train_5_20251119_220510/model_epoch_140.pt\n",
      "\n",
      "Epoch 141/200\n",
      "train loss: 0.0364 | train acc: 98.73%\n",
      "test loss:  0.3213 | test acc:  92.17%\n",
      "\n",
      "Epoch 142/200\n",
      "train loss: 0.0377 | train acc: 98.69%\n",
      "test loss:  0.3665 | test acc:  90.33%\n",
      "\n",
      "Epoch 143/200\n",
      "train loss: 0.0340 | train acc: 98.82%\n",
      "test loss:  0.3904 | test acc:  90.85%\n",
      "\n",
      "Epoch 144/200\n",
      "train loss: 0.0382 | train acc: 98.56%\n",
      "test loss:  0.3172 | test acc:  91.93%\n",
      "\n",
      "Epoch 145/200\n",
      "train loss: 0.0359 | train acc: 98.72%\n",
      "test loss:  0.3358 | test acc:  91.74%\n",
      "\n",
      "Epoch 146/200\n",
      "train loss: 0.0386 | train acc: 98.63%\n",
      "test loss:  0.5681 | test acc:  86.65%\n",
      "\n",
      "Epoch 147/200\n",
      "train loss: 0.0378 | train acc: 98.67%\n",
      "test loss:  0.4705 | test acc:  87.56%\n",
      "\n",
      "Epoch 148/200\n",
      "train loss: 0.0342 | train acc: 98.82%\n",
      "test loss:  0.4076 | test acc:  90.44%\n",
      "\n",
      "Epoch 149/200\n",
      "train loss: 0.0279 | train acc: 99.06%\n",
      "test loss:  0.5892 | test acc:  87.59%\n",
      "\n",
      "Epoch 150/200\n",
      "train loss: 0.0403 | train acc: 98.66%\n",
      "test loss:  0.5760 | test acc:  87.19%\n",
      "\n",
      "Epoch 151/200\n",
      "train loss: 0.0316 | train acc: 98.84%\n",
      "test loss:  0.3098 | test acc:  92.44%\n",
      "\n",
      "Epoch 152/200\n",
      "train loss: 0.0391 | train acc: 98.62%\n",
      "test loss:  1.1881 | test acc:  78.63%\n",
      "\n",
      "Epoch 153/200\n",
      "train loss: 0.0415 | train acc: 98.47%\n",
      "test loss:  0.4462 | test acc:  89.19%\n",
      "\n",
      "Epoch 154/200\n",
      "train loss: 0.0334 | train acc: 98.86%\n",
      "test loss:  0.4298 | test acc:  89.93%\n",
      "\n",
      "Epoch 155/200\n",
      "train loss: 0.0334 | train acc: 98.85%\n",
      "test loss:  0.5431 | test acc:  86.93%\n",
      "\n",
      "Epoch 156/200\n",
      "train loss: 0.0363 | train acc: 98.88%\n",
      "test loss:  0.6389 | test acc:  85.65%\n",
      "\n",
      "Epoch 157/200\n",
      "train loss: 0.0376 | train acc: 98.77%\n",
      "test loss:  0.3192 | test acc:  91.98%\n",
      "\n",
      "Epoch 158/200\n",
      "train loss: 0.0374 | train acc: 98.69%\n",
      "test loss:  0.8451 | test acc:  83.76%\n",
      "\n",
      "Epoch 159/200\n",
      "train loss: 0.0319 | train acc: 98.91%\n",
      "test loss:  0.3304 | test acc:  91.93%\n",
      "\n",
      "Epoch 160/200\n",
      "train loss: 0.0254 | train acc: 99.22%\n",
      "test loss:  0.4124 | test acc:  89.98%\n",
      "checkpoint saved: checkpoints/train_5_20251119_220510/model_epoch_160.pt\n",
      "\n",
      "Epoch 161/200\n",
      "train loss: 0.0337 | train acc: 98.74%\n",
      "test loss:  0.3188 | test acc:  91.80%\n",
      "\n",
      "Epoch 162/200\n",
      "train loss: 0.0345 | train acc: 98.81%\n",
      "test loss:  0.3670 | test acc:  91.56%\n",
      "\n",
      "Epoch 163/200\n",
      "train loss: 0.0334 | train acc: 98.99%\n",
      "test loss:  0.4730 | test acc:  89.09%\n",
      "\n",
      "Epoch 164/200\n",
      "train loss: 0.0397 | train acc: 98.71%\n",
      "test loss:  0.3476 | test acc:  91.44%\n",
      "\n",
      "Epoch 165/200\n",
      "train loss: 0.0308 | train acc: 98.92%\n",
      "test loss:  0.4383 | test acc:  89.93%\n",
      "\n",
      "Epoch 166/200\n",
      "train loss: 0.0333 | train acc: 98.83%\n",
      "test loss:  0.4227 | test acc:  89.70%\n",
      "\n",
      "Epoch 167/200\n",
      "train loss: 0.0322 | train acc: 98.87%\n",
      "test loss:  0.7921 | test acc:  83.20%\n",
      "\n",
      "Epoch 168/200\n",
      "train loss: 0.0311 | train acc: 98.94%\n",
      "test loss:  0.7455 | test acc:  84.89%\n",
      "\n",
      "Epoch 169/200\n",
      "train loss: 0.0305 | train acc: 99.00%\n",
      "test loss:  0.3592 | test acc:  91.15%\n",
      "\n",
      "Epoch 170/200\n",
      "train loss: 0.0307 | train acc: 98.96%\n",
      "test loss:  0.5548 | test acc:  88.63%\n",
      "\n",
      "Epoch 171/200\n",
      "train loss: 0.0283 | train acc: 98.99%\n",
      "test loss:  0.6261 | test acc:  85.37%\n",
      "\n",
      "Epoch 172/200\n",
      "train loss: 0.0337 | train acc: 98.78%\n",
      "test loss:  0.3409 | test acc:  91.46%\n",
      "\n",
      "Epoch 173/200\n",
      "train loss: 0.0302 | train acc: 98.90%\n",
      "test loss:  0.3682 | test acc:  91.13%\n",
      "\n",
      "Epoch 174/200\n",
      "train loss: 0.0288 | train acc: 99.00%\n",
      "test loss:  0.2762 | test acc:  92.91%\n",
      "\n",
      "Epoch 175/200\n",
      "train loss: 0.0282 | train acc: 98.99%\n",
      "test loss:  0.3690 | test acc:  91.17%\n",
      "\n",
      "Epoch 176/200\n",
      "train loss: 0.0322 | train acc: 98.94%\n",
      "test loss:  0.6873 | test acc:  85.46%\n",
      "\n",
      "Epoch 177/200\n",
      "train loss: 0.0274 | train acc: 99.06%\n",
      "test loss:  0.3422 | test acc:  92.19%\n",
      "\n",
      "Epoch 178/200\n",
      "train loss: 0.0304 | train acc: 98.99%\n",
      "test loss:  0.3787 | test acc:  91.07%\n",
      "\n",
      "Epoch 179/200\n",
      "train loss: 0.0300 | train acc: 99.03%\n",
      "test loss:  0.3556 | test acc:  91.17%\n",
      "\n",
      "Epoch 180/200\n",
      "train loss: 0.0317 | train acc: 98.94%\n",
      "test loss:  0.3174 | test acc:  92.26%\n",
      "checkpoint saved: checkpoints/train_5_20251119_220510/model_epoch_180.pt\n",
      "\n",
      "Epoch 181/200\n",
      "train loss: 0.0343 | train acc: 98.81%\n",
      "test loss:  0.3957 | test acc:  90.70%\n",
      "\n",
      "Epoch 182/200\n",
      "train loss: 0.0377 | train acc: 98.72%\n",
      "test loss:  0.3016 | test acc:  92.57%\n",
      "\n",
      "Epoch 183/200\n",
      "train loss: 0.0266 | train acc: 99.10%\n",
      "test loss:  0.3268 | test acc:  92.04%\n",
      "\n",
      "Epoch 184/200\n",
      "train loss: 0.0355 | train acc: 98.84%\n",
      "test loss:  0.4555 | test acc:  89.50%\n",
      "\n",
      "Epoch 185/200\n",
      "train loss: 0.0283 | train acc: 99.08%\n",
      "test loss:  0.9013 | test acc:  83.24%\n",
      "\n",
      "Epoch 186/200\n",
      "train loss: 0.0260 | train acc: 99.09%\n",
      "test loss:  1.8008 | test acc:  75.17%\n",
      "\n",
      "Epoch 187/200\n",
      "train loss: 0.0326 | train acc: 98.94%\n",
      "test loss:  2.6426 | test acc:  64.93%\n",
      "\n",
      "Epoch 188/200\n",
      "train loss: 0.0536 | train acc: 98.30%\n",
      "test loss:  0.3656 | test acc:  90.65%\n",
      "\n",
      "Epoch 189/200\n",
      "train loss: 0.0280 | train acc: 99.02%\n",
      "test loss:  0.2809 | test acc:  93.00%\n",
      "\n",
      "Epoch 190/200\n",
      "train loss: 0.0259 | train acc: 99.10%\n",
      "test loss:  0.3676 | test acc:  91.07%\n",
      "\n",
      "Epoch 191/200\n",
      "train loss: 0.0272 | train acc: 99.07%\n",
      "test loss:  0.3308 | test acc:  92.06%\n",
      "\n",
      "Epoch 192/200\n",
      "train loss: 0.0351 | train acc: 98.88%\n",
      "test loss:  0.5710 | test acc:  88.44%\n",
      "\n",
      "Epoch 193/200\n",
      "train loss: 0.0250 | train acc: 99.14%\n",
      "test loss:  0.2965 | test acc:  92.93%\n",
      "\n",
      "Epoch 194/200\n",
      "train loss: 0.0218 | train acc: 99.29%\n",
      "test loss:  1.4921 | test acc:  76.87%\n",
      "\n",
      "Epoch 195/200\n",
      "train loss: 0.0207 | train acc: 99.30%\n",
      "test loss:  0.3964 | test acc:  91.06%\n",
      "\n",
      "Epoch 196/200\n",
      "train loss: 0.0275 | train acc: 99.01%\n",
      "test loss:  1.3542 | test acc:  78.28%\n",
      "\n",
      "Epoch 197/200\n",
      "train loss: 0.0265 | train acc: 99.06%\n",
      "test loss:  0.4454 | test acc:  89.56%\n",
      "\n",
      "Epoch 198/200\n",
      "train loss: 0.0263 | train acc: 99.07%\n",
      "test loss:  0.7842 | test acc:  85.17%\n",
      "\n",
      "Epoch 199/200\n",
      "train loss: 0.0253 | train acc: 99.16%\n",
      "test loss:  0.3151 | test acc:  92.80%\n",
      "\n",
      "Epoch 200/200\n",
      "train loss: 0.0279 | train acc: 99.06%\n",
      "test loss:  0.6641 | test acc:  87.19%\n",
      "checkpoint saved: checkpoints/train_5_20251119_220510/model_epoch_200.pt\n",
      "\n",
      "final checkpoint saved: checkpoints/train_5_20251119_220510/model_final.pt\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "# tensorboard setup\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/train_{}_{}'.format(MODEL_NUMBER, timestamp))\n",
    "\n",
    "checkpoint_dir = f'checkpoints/train_{MODEL_NUMBER}_{timestamp}'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "EPOCHS = 200\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "    \n",
    "\n",
    "\n",
    "    train_loss, train_acc = train_one_epoch()\n",
    "    \n",
    "    test_loss, test_acc = test_one_epoch()\n",
    "    \n",
    "    print(f'train loss: {train_loss:.4f} | train acc: {train_acc:.2f}%')\n",
    "    print(f'test loss:  {test_loss:.4f} | test acc:  {test_acc:.2f}%')\n",
    "    \n",
    "    # log data\n",
    "    writer.add_scalar('loss/1_train', train_loss, epoch + 1)\n",
    "    writer.add_scalar('loss/2_test', test_loss, epoch + 1)\n",
    "    writer.add_scalar('accuracy/1_train', train_acc, epoch + 1)\n",
    "    writer.add_scalar('accuracy/2_test', test_acc, epoch + 1)\n",
    "    writer.flush()\n",
    "    \n",
    "    # checkpoint every 20 epochs\n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'model_epoch_{epoch + 1}.pt')\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "        print(f'checkpoint saved: {checkpoint_path}')\n",
    "    \n",
    "    print()\n",
    "\n",
    "# save final model\n",
    "final_checkpoint_path = os.path.join(checkpoint_dir, f'model_final.pt')\n",
    "torch.save(model.state_dict(), final_checkpoint_path)\n",
    "print(f'final checkpoint saved: {final_checkpoint_path}')\n",
    "\n",
    "writer.close()\n",
    "print('Complete')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
