{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42efbf30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 21600\n",
      "test size: 5400\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "MODEL_NUMBER = 4\n",
    "\n",
    "    \n",
    "# seed so random stuff isnt random\n",
    "SEED = 100\n",
    "\n",
    "# transforms\n",
    "transform = transforms.Compose([\n",
    "\n",
    "    transforms.RandomResizedCrop(64, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "dataset = torchvision.datasets.EuroSAT(root='./data', download=True, transform=transform)\n",
    "\n",
    "# split into train, test\n",
    "# 80% train, 20% test \n",
    "train_ratio = 0.8\n",
    "test_ratio = 0.2\n",
    "\n",
    "\n",
    "total_size = len(dataset)\n",
    "train_size = int(total_size * train_ratio)\n",
    "test_size = total_size - train_size\n",
    "\n",
    "\n",
    "train_dataset, test_dataset = random_split(\n",
    "    dataset, [train_size, test_size],\n",
    "    generator=torch.Generator().manual_seed(SEED)\n",
    ")\n",
    "\n",
    "print(f\"train: {len(train_dataset)}\")\n",
    "print(f\"test size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa92cd06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Model(\n",
      "  (relu): ReLU()\n",
      "  (c1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (c2): Conv2d(8, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (c3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (c4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (c5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=65536, out_features=1024, bias=True)\n",
      "  (dropout1): Dropout(p=0.5, inplace=False)\n",
      "  (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n",
      "Total parameters: 67764938\n"
     ]
    }
   ],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "        self.c1 = torch.nn.Conv2d(3, 8, 3, padding=1)\n",
    "        self.c2 = torch.nn.Conv2d(8, 32, 3, padding=1)\n",
    "        self.c3 = torch.nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.maxpool1 = torch.nn.MaxPool2d(2)\n",
    "        self.c4 = torch.nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.maxpool2 = torch.nn.MaxPool2d(2)\n",
    "        self.c5 = torch.nn.Conv2d(128, 256, 3, padding=1)\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(256 * 16 * 16, 1024)\n",
    "        self.dropout1 = torch.nn.Dropout(0.5)\n",
    "        self.fc2 = torch.nn.Linear(1024, 256)\n",
    "        self.dropout2 = torch.nn.Dropout(0.5)\n",
    "        self.fc3 = torch.nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.c1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.c2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.c3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.c4(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.c5(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = Model()\n",
    "print(f\"Model: {model}\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters())}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "499a7ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# dataloaders\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=128, \n",
    "    shuffle=True,\n",
    "    pin_memory=True, # for use on gpu\n",
    "    num_workers=4 # arbitrarily chosen. some sources recommend 4 per gpu\n",
    ")\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=128, \n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b139e4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "if device == \"cuda\":\n",
    "    model.to(device, non_blocking=True) # according to pytorch docs we can do this if memory is pinned\n",
    "else:  \n",
    "    model.to(device)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "205d254c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch():\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def test_one_epoch():\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa66e8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "train loss: 1.8162 | test acc: 29.27%\n",
      "test loss:  1.5721 | test acc:  38.35%\n",
      "\n",
      "Epoch 2/200\n",
      "train loss: 1.2666 | test acc: 52.45%\n",
      "test loss:  1.0119 | test acc:  62.24%\n",
      "\n",
      "Epoch 3/200\n",
      "train loss: 1.0532 | test acc: 61.44%\n",
      "test loss:  1.0834 | test acc:  59.89%\n",
      "\n",
      "Epoch 4/200\n",
      "train loss: 0.9383 | test acc: 65.88%\n",
      "test loss:  0.8940 | test acc:  66.19%\n",
      "\n",
      "Epoch 5/200\n",
      "train loss: 0.8689 | test acc: 68.61%\n",
      "test loss:  0.7655 | test acc:  71.04%\n",
      "\n",
      "Epoch 6/200\n",
      "train loss: 0.7934 | test acc: 71.40%\n",
      "test loss:  0.7172 | test acc:  73.72%\n",
      "\n",
      "Epoch 7/200\n",
      "train loss: 0.7363 | test acc: 73.56%\n",
      "test loss:  0.6779 | test acc:  75.35%\n",
      "\n",
      "Epoch 8/200\n",
      "train loss: 0.7140 | test acc: 74.73%\n",
      "test loss:  0.6536 | test acc:  76.30%\n",
      "\n",
      "Epoch 9/200\n",
      "train loss: 0.6706 | test acc: 76.46%\n",
      "test loss:  0.6471 | test acc:  76.70%\n",
      "\n",
      "Epoch 10/200\n",
      "train loss: 0.6641 | test acc: 77.08%\n",
      "test loss:  0.5856 | test acc:  78.56%\n",
      "\n",
      "Epoch 11/200\n",
      "train loss: 0.6031 | test acc: 78.83%\n",
      "test loss:  0.5490 | test acc:  80.35%\n",
      "\n",
      "Epoch 12/200\n",
      "train loss: 0.5844 | test acc: 79.78%\n",
      "test loss:  0.5528 | test acc:  79.91%\n",
      "\n",
      "Epoch 13/200\n",
      "train loss: 0.5549 | test acc: 80.79%\n",
      "test loss:  0.5345 | test acc:  80.93%\n",
      "\n",
      "Epoch 14/200\n",
      "train loss: 0.5410 | test acc: 81.24%\n",
      "test loss:  0.5121 | test acc:  82.09%\n",
      "\n",
      "Epoch 15/200\n",
      "train loss: 0.5222 | test acc: 81.93%\n",
      "test loss:  0.5094 | test acc:  82.37%\n",
      "\n",
      "Epoch 16/200\n",
      "train loss: 0.4883 | test acc: 83.15%\n",
      "test loss:  0.4843 | test acc:  83.59%\n",
      "\n",
      "Epoch 17/200\n",
      "train loss: 0.4752 | test acc: 83.86%\n",
      "test loss:  0.4653 | test acc:  83.50%\n",
      "\n",
      "Epoch 18/200\n",
      "train loss: 0.4660 | test acc: 84.08%\n",
      "test loss:  0.4400 | test acc:  84.41%\n",
      "\n",
      "Epoch 19/200\n",
      "train loss: 0.4469 | test acc: 84.80%\n",
      "test loss:  0.4700 | test acc:  83.44%\n",
      "\n",
      "Epoch 20/200\n",
      "train loss: 0.4445 | test acc: 84.79%\n",
      "test loss:  0.4600 | test acc:  83.91%\n",
      "checkpoint saved: checkpoints/train_4_20251119_115150/model_epoch_20.pt\n",
      "\n",
      "Epoch 21/200\n",
      "train loss: 0.4151 | test acc: 85.88%\n",
      "test loss:  0.4164 | test acc:  85.61%\n",
      "\n",
      "Epoch 22/200\n",
      "train loss: 0.4103 | test acc: 86.25%\n",
      "test loss:  0.4129 | test acc:  85.26%\n",
      "\n",
      "Epoch 23/200\n",
      "train loss: 0.4017 | test acc: 86.45%\n",
      "test loss:  0.4345 | test acc:  85.04%\n",
      "\n",
      "Epoch 24/200\n",
      "train loss: 0.4020 | test acc: 86.35%\n",
      "test loss:  0.4115 | test acc:  86.07%\n",
      "\n",
      "Epoch 25/200\n",
      "train loss: 0.3783 | test acc: 87.32%\n",
      "test loss:  0.3885 | test acc:  86.43%\n",
      "\n",
      "Epoch 26/200\n",
      "train loss: 0.3799 | test acc: 87.30%\n",
      "test loss:  0.3707 | test acc:  87.63%\n",
      "\n",
      "Epoch 27/200\n",
      "train loss: 0.3663 | test acc: 87.67%\n",
      "test loss:  0.4193 | test acc:  85.93%\n",
      "\n",
      "Epoch 28/200\n",
      "train loss: 0.3510 | test acc: 88.13%\n",
      "test loss:  0.3675 | test acc:  87.59%\n",
      "\n",
      "Epoch 29/200\n",
      "train loss: 0.3427 | test acc: 88.53%\n",
      "test loss:  0.3987 | test acc:  86.19%\n",
      "\n",
      "Epoch 30/200\n",
      "train loss: 0.3428 | test acc: 88.64%\n",
      "test loss:  0.3993 | test acc:  86.50%\n",
      "\n",
      "Epoch 31/200\n",
      "train loss: 0.3266 | test acc: 88.93%\n",
      "test loss:  0.3685 | test acc:  86.20%\n",
      "\n",
      "Epoch 32/200\n",
      "train loss: 0.3293 | test acc: 89.01%\n",
      "test loss:  0.3337 | test acc:  88.61%\n",
      "\n",
      "Epoch 33/200\n",
      "train loss: 0.3188 | test acc: 89.32%\n",
      "test loss:  0.3429 | test acc:  88.15%\n",
      "\n",
      "Epoch 34/200\n",
      "train loss: 0.3188 | test acc: 89.16%\n",
      "test loss:  0.3519 | test acc:  87.89%\n",
      "\n",
      "Epoch 35/200\n",
      "train loss: 0.3109 | test acc: 89.49%\n",
      "test loss:  0.3569 | test acc:  87.67%\n",
      "\n",
      "Epoch 36/200\n",
      "train loss: 0.2998 | test acc: 89.96%\n",
      "test loss:  0.3338 | test acc:  88.67%\n",
      "\n",
      "Epoch 37/200\n",
      "train loss: 0.3068 | test acc: 89.62%\n",
      "test loss:  0.3265 | test acc:  88.43%\n",
      "\n",
      "Epoch 38/200\n",
      "train loss: 0.2830 | test acc: 90.39%\n",
      "test loss:  0.3545 | test acc:  87.72%\n",
      "\n",
      "Epoch 39/200\n",
      "train loss: 0.2988 | test acc: 90.04%\n",
      "test loss:  0.3399 | test acc:  88.31%\n",
      "\n",
      "Epoch 40/200\n",
      "train loss: 0.2790 | test acc: 90.85%\n",
      "test loss:  0.3265 | test acc:  88.67%\n",
      "checkpoint saved: checkpoints/train_4_20251119_115150/model_epoch_40.pt\n",
      "\n",
      "Epoch 41/200\n",
      "train loss: 0.2844 | test acc: 90.51%\n",
      "test loss:  0.3436 | test acc:  88.31%\n",
      "\n",
      "Epoch 42/200\n",
      "train loss: 0.2716 | test acc: 90.78%\n",
      "test loss:  0.3316 | test acc:  89.06%\n",
      "\n",
      "Epoch 43/200\n",
      "train loss: 0.2735 | test acc: 90.88%\n",
      "test loss:  0.3490 | test acc:  89.20%\n",
      "\n",
      "Epoch 44/200\n",
      "train loss: 0.2620 | test acc: 91.22%\n",
      "test loss:  0.3291 | test acc:  89.07%\n",
      "\n",
      "Epoch 45/200\n",
      "train loss: 0.2693 | test acc: 90.95%\n",
      "test loss:  0.3108 | test acc:  89.19%\n",
      "\n",
      "Epoch 46/200\n",
      "train loss: 0.2568 | test acc: 91.42%\n",
      "test loss:  0.3235 | test acc:  89.09%\n",
      "\n",
      "Epoch 47/200\n",
      "train loss: 0.2467 | test acc: 91.92%\n",
      "test loss:  0.3315 | test acc:  89.02%\n",
      "\n",
      "Epoch 48/200\n",
      "train loss: 0.2518 | test acc: 91.53%\n",
      "test loss:  0.2978 | test acc:  89.41%\n",
      "\n",
      "Epoch 49/200\n",
      "train loss: 0.2457 | test acc: 91.82%\n",
      "test loss:  0.2985 | test acc:  89.76%\n",
      "\n",
      "Epoch 50/200\n",
      "train loss: 0.2427 | test acc: 92.00%\n",
      "test loss:  0.3217 | test acc:  89.44%\n",
      "\n",
      "Epoch 51/200\n",
      "train loss: 0.2507 | test acc: 91.72%\n",
      "test loss:  0.3516 | test acc:  89.09%\n",
      "\n",
      "Epoch 52/200\n",
      "train loss: 0.2344 | test acc: 92.12%\n",
      "test loss:  0.3287 | test acc:  88.83%\n",
      "\n",
      "Epoch 53/200\n",
      "train loss: 0.2328 | test acc: 91.96%\n",
      "test loss:  0.3282 | test acc:  89.37%\n",
      "\n",
      "Epoch 54/200\n",
      "train loss: 0.2393 | test acc: 91.96%\n",
      "test loss:  0.3158 | test acc:  89.72%\n",
      "\n",
      "Epoch 55/200\n",
      "train loss: 0.2189 | test acc: 92.51%\n",
      "test loss:  0.3288 | test acc:  89.37%\n",
      "\n",
      "Epoch 56/200\n",
      "train loss: 0.2305 | test acc: 92.12%\n",
      "test loss:  0.2878 | test acc:  90.35%\n",
      "\n",
      "Epoch 57/200\n",
      "train loss: 0.2253 | test acc: 92.54%\n",
      "test loss:  0.2946 | test acc:  90.07%\n",
      "\n",
      "Epoch 58/200\n",
      "train loss: 0.2117 | test acc: 92.77%\n",
      "test loss:  0.3150 | test acc:  89.93%\n",
      "\n",
      "Epoch 59/200\n",
      "train loss: 0.2139 | test acc: 92.91%\n",
      "test loss:  0.3100 | test acc:  89.80%\n",
      "\n",
      "Epoch 60/200\n",
      "train loss: 0.2159 | test acc: 92.62%\n",
      "test loss:  0.2809 | test acc:  91.19%\n",
      "checkpoint saved: checkpoints/train_4_20251119_115150/model_epoch_60.pt\n",
      "\n",
      "Epoch 61/200\n",
      "train loss: 0.2176 | test acc: 92.72%\n",
      "test loss:  0.3292 | test acc:  90.31%\n",
      "\n",
      "Epoch 62/200\n",
      "train loss: 0.2153 | test acc: 92.92%\n",
      "test loss:  0.2831 | test acc:  90.57%\n",
      "\n",
      "Epoch 63/200\n",
      "train loss: 0.2054 | test acc: 93.08%\n",
      "test loss:  0.2948 | test acc:  90.20%\n",
      "\n",
      "Epoch 64/200\n",
      "train loss: 0.2060 | test acc: 92.90%\n",
      "test loss:  0.2717 | test acc:  91.17%\n",
      "\n",
      "Epoch 65/200\n",
      "train loss: 0.2127 | test acc: 92.80%\n",
      "test loss:  0.2877 | test acc:  90.11%\n",
      "\n",
      "Epoch 66/200\n",
      "train loss: 0.2081 | test acc: 92.87%\n",
      "test loss:  0.3090 | test acc:  90.04%\n",
      "\n",
      "Epoch 67/200\n",
      "train loss: 0.2041 | test acc: 93.12%\n",
      "test loss:  0.2958 | test acc:  90.09%\n",
      "\n",
      "Epoch 68/200\n",
      "train loss: 0.2063 | test acc: 92.91%\n",
      "test loss:  0.2941 | test acc:  90.26%\n",
      "\n",
      "Epoch 69/200\n",
      "train loss: 0.2042 | test acc: 93.42%\n",
      "test loss:  0.2935 | test acc:  90.46%\n",
      "\n",
      "Epoch 70/200\n",
      "train loss: 0.1899 | test acc: 93.57%\n",
      "test loss:  0.2819 | test acc:  90.83%\n",
      "\n",
      "Epoch 71/200\n",
      "train loss: 0.2044 | test acc: 93.18%\n",
      "test loss:  0.2751 | test acc:  90.74%\n",
      "\n",
      "Epoch 72/200\n",
      "train loss: 0.2033 | test acc: 93.17%\n",
      "test loss:  0.3013 | test acc:  90.41%\n",
      "\n",
      "Epoch 73/200\n",
      "train loss: 0.1918 | test acc: 93.45%\n",
      "test loss:  0.2777 | test acc:  90.74%\n",
      "\n",
      "Epoch 74/200\n",
      "train loss: 0.1906 | test acc: 93.60%\n",
      "test loss:  0.2721 | test acc:  91.50%\n",
      "\n",
      "Epoch 75/200\n",
      "train loss: 0.1767 | test acc: 94.03%\n",
      "test loss:  0.2909 | test acc:  90.61%\n",
      "\n",
      "Epoch 76/200\n",
      "train loss: 0.1927 | test acc: 93.56%\n",
      "test loss:  0.2805 | test acc:  91.44%\n",
      "\n",
      "Epoch 77/200\n",
      "train loss: 0.1766 | test acc: 94.21%\n",
      "test loss:  0.2484 | test acc:  91.85%\n",
      "\n",
      "Epoch 78/200\n",
      "train loss: 0.1849 | test acc: 93.68%\n",
      "test loss:  0.2911 | test acc:  90.93%\n",
      "\n",
      "Epoch 79/200\n",
      "train loss: 0.1825 | test acc: 93.82%\n",
      "test loss:  0.2797 | test acc:  91.41%\n",
      "\n",
      "Epoch 80/200\n",
      "train loss: 0.1903 | test acc: 93.80%\n",
      "test loss:  0.2907 | test acc:  90.63%\n",
      "checkpoint saved: checkpoints/train_4_20251119_115150/model_epoch_80.pt\n",
      "\n",
      "Epoch 81/200\n",
      "train loss: 0.1928 | test acc: 93.57%\n",
      "test loss:  0.2630 | test acc:  91.17%\n",
      "\n",
      "Epoch 82/200\n",
      "train loss: 0.1855 | test acc: 93.82%\n",
      "test loss:  0.2992 | test acc:  90.37%\n",
      "\n",
      "Epoch 83/200\n",
      "train loss: 0.1799 | test acc: 93.98%\n",
      "test loss:  0.2741 | test acc:  91.41%\n",
      "\n",
      "Epoch 84/200\n",
      "train loss: 0.1754 | test acc: 94.02%\n",
      "test loss:  0.2566 | test acc:  91.63%\n",
      "\n",
      "Epoch 85/200\n",
      "train loss: 0.1785 | test acc: 94.07%\n",
      "test loss:  0.2634 | test acc:  91.41%\n",
      "\n",
      "Epoch 86/200\n",
      "train loss: 0.1748 | test acc: 94.02%\n",
      "test loss:  0.2803 | test acc:  90.57%\n",
      "\n",
      "Epoch 87/200\n",
      "train loss: 0.1823 | test acc: 93.98%\n",
      "test loss:  0.2980 | test acc:  90.39%\n",
      "\n",
      "Epoch 88/200\n",
      "train loss: 0.1630 | test acc: 94.28%\n",
      "test loss:  0.2581 | test acc:  92.02%\n",
      "\n",
      "Epoch 89/200\n",
      "train loss: 0.1723 | test acc: 94.21%\n",
      "test loss:  0.2653 | test acc:  91.24%\n",
      "\n",
      "Epoch 90/200\n",
      "train loss: 0.1662 | test acc: 94.45%\n",
      "test loss:  0.2846 | test acc:  91.28%\n",
      "\n",
      "Epoch 91/200\n",
      "train loss: 0.1725 | test acc: 94.21%\n",
      "test loss:  0.2552 | test acc:  91.89%\n",
      "\n",
      "Epoch 92/200\n",
      "train loss: 0.1682 | test acc: 94.55%\n",
      "test loss:  0.2889 | test acc:  90.67%\n",
      "\n",
      "Epoch 93/200\n",
      "train loss: 0.1672 | test acc: 94.44%\n",
      "test loss:  0.2489 | test acc:  91.81%\n",
      "\n",
      "Epoch 94/200\n",
      "train loss: 0.1672 | test acc: 94.49%\n",
      "test loss:  0.2690 | test acc:  91.24%\n",
      "\n",
      "Epoch 95/200\n",
      "train loss: 0.1578 | test acc: 94.76%\n",
      "test loss:  0.2706 | test acc:  91.31%\n",
      "\n",
      "Epoch 96/200\n",
      "train loss: 0.1565 | test acc: 94.79%\n",
      "test loss:  0.2983 | test acc:  91.46%\n",
      "\n",
      "Epoch 97/200\n",
      "train loss: 0.1764 | test acc: 94.21%\n",
      "test loss:  0.2726 | test acc:  91.80%\n",
      "\n",
      "Epoch 98/200\n",
      "train loss: 0.1674 | test acc: 94.63%\n",
      "test loss:  0.2774 | test acc:  91.13%\n",
      "\n",
      "Epoch 99/200\n",
      "train loss: 0.1583 | test acc: 94.80%\n",
      "test loss:  0.2676 | test acc:  91.44%\n",
      "\n",
      "Epoch 100/200\n",
      "train loss: 0.1646 | test acc: 94.42%\n",
      "test loss:  0.2665 | test acc:  91.63%\n",
      "checkpoint saved: checkpoints/train_4_20251119_115150/model_epoch_100.pt\n",
      "\n",
      "Epoch 101/200\n",
      "train loss: 0.1623 | test acc: 94.59%\n",
      "test loss:  0.2927 | test acc:  91.06%\n",
      "\n",
      "Epoch 102/200\n",
      "train loss: 0.1550 | test acc: 94.76%\n",
      "test loss:  0.2708 | test acc:  91.67%\n",
      "\n",
      "Epoch 103/200\n",
      "train loss: 0.1644 | test acc: 94.72%\n",
      "test loss:  0.2589 | test acc:  91.74%\n",
      "\n",
      "Epoch 104/200\n",
      "train loss: 0.1528 | test acc: 94.94%\n",
      "test loss:  0.2472 | test acc:  92.37%\n",
      "\n",
      "Epoch 105/200\n",
      "train loss: 0.1477 | test acc: 95.07%\n",
      "test loss:  0.2733 | test acc:  91.70%\n",
      "\n",
      "Epoch 106/200\n",
      "train loss: 0.1510 | test acc: 94.82%\n",
      "test loss:  0.2326 | test acc:  92.93%\n",
      "\n",
      "Epoch 107/200\n",
      "train loss: 0.1610 | test acc: 94.59%\n",
      "test loss:  0.2894 | test acc:  90.87%\n",
      "\n",
      "Epoch 108/200\n",
      "train loss: 0.1609 | test acc: 94.70%\n",
      "test loss:  0.2656 | test acc:  91.56%\n",
      "\n",
      "Epoch 109/200\n",
      "train loss: 0.1684 | test acc: 94.26%\n",
      "test loss:  0.2871 | test acc:  90.91%\n",
      "\n",
      "Epoch 110/200\n",
      "train loss: 0.1582 | test acc: 94.73%\n",
      "test loss:  0.2741 | test acc:  91.85%\n",
      "\n",
      "Epoch 111/200\n",
      "train loss: 0.1528 | test acc: 94.75%\n",
      "test loss:  0.2703 | test acc:  91.46%\n",
      "\n",
      "Epoch 112/200\n",
      "train loss: 0.1442 | test acc: 94.98%\n",
      "test loss:  0.2503 | test acc:  92.11%\n",
      "\n",
      "Epoch 113/200\n",
      "train loss: 0.1581 | test acc: 94.86%\n",
      "test loss:  0.2551 | test acc:  91.85%\n",
      "\n",
      "Epoch 114/200\n",
      "train loss: 0.1443 | test acc: 95.26%\n",
      "test loss:  0.2522 | test acc:  92.17%\n",
      "\n",
      "Epoch 115/200\n",
      "train loss: 0.1404 | test acc: 95.28%\n",
      "test loss:  0.2693 | test acc:  91.87%\n",
      "\n",
      "Epoch 116/200\n",
      "train loss: 0.1439 | test acc: 95.06%\n",
      "test loss:  0.2698 | test acc:  92.30%\n",
      "\n",
      "Epoch 117/200\n",
      "train loss: 0.1430 | test acc: 95.33%\n",
      "test loss:  0.2514 | test acc:  92.07%\n",
      "\n",
      "Epoch 118/200\n",
      "train loss: 0.1415 | test acc: 95.44%\n",
      "test loss:  0.2427 | test acc:  92.30%\n",
      "\n",
      "Epoch 119/200\n",
      "train loss: 0.1506 | test acc: 95.03%\n",
      "test loss:  0.2456 | test acc:  92.33%\n",
      "\n",
      "Epoch 120/200\n",
      "train loss: 0.1481 | test acc: 95.24%\n",
      "test loss:  0.2469 | test acc:  92.30%\n",
      "checkpoint saved: checkpoints/train_4_20251119_115150/model_epoch_120.pt\n",
      "\n",
      "Epoch 121/200\n",
      "train loss: 0.1426 | test acc: 95.36%\n",
      "test loss:  0.2430 | test acc:  92.67%\n",
      "\n",
      "Epoch 122/200\n",
      "train loss: 0.1430 | test acc: 95.29%\n",
      "test loss:  0.2286 | test acc:  92.11%\n",
      "\n",
      "Epoch 123/200\n",
      "train loss: 0.1427 | test acc: 95.18%\n",
      "test loss:  0.2227 | test acc:  93.00%\n",
      "\n",
      "Epoch 124/200\n",
      "train loss: 0.1360 | test acc: 95.38%\n",
      "test loss:  0.2618 | test acc:  91.70%\n",
      "\n",
      "Epoch 125/200\n",
      "train loss: 0.1363 | test acc: 95.42%\n",
      "test loss:  0.2920 | test acc:  91.04%\n",
      "\n",
      "Epoch 126/200\n",
      "train loss: 0.1456 | test acc: 95.28%\n",
      "test loss:  0.2711 | test acc:  91.74%\n",
      "\n",
      "Epoch 127/200\n",
      "train loss: 0.1468 | test acc: 95.31%\n",
      "test loss:  0.2356 | test acc:  91.85%\n",
      "\n",
      "Epoch 128/200\n",
      "train loss: 0.1441 | test acc: 95.34%\n",
      "test loss:  0.2551 | test acc:  91.80%\n",
      "\n",
      "Epoch 129/200\n",
      "train loss: 0.1405 | test acc: 95.31%\n",
      "test loss:  0.2456 | test acc:  92.46%\n",
      "\n",
      "Epoch 130/200\n",
      "train loss: 0.1396 | test acc: 95.36%\n",
      "test loss:  0.2778 | test acc:  90.85%\n",
      "\n",
      "Epoch 131/200\n",
      "train loss: 0.1530 | test acc: 94.96%\n",
      "test loss:  0.2631 | test acc:  91.52%\n",
      "\n",
      "Epoch 132/200\n",
      "train loss: 0.1443 | test acc: 95.35%\n",
      "test loss:  0.2271 | test acc:  92.78%\n",
      "\n",
      "Epoch 133/200\n",
      "train loss: 0.1404 | test acc: 95.55%\n",
      "test loss:  0.2608 | test acc:  91.91%\n",
      "\n",
      "Epoch 134/200\n",
      "train loss: 0.1398 | test acc: 95.25%\n",
      "test loss:  0.2653 | test acc:  92.04%\n",
      "\n",
      "Epoch 135/200\n",
      "train loss: 0.1386 | test acc: 95.49%\n",
      "test loss:  0.2470 | test acc:  92.24%\n",
      "\n",
      "Epoch 136/200\n",
      "train loss: 0.1367 | test acc: 95.50%\n",
      "test loss:  0.2735 | test acc:  91.76%\n",
      "\n",
      "Epoch 137/200\n",
      "train loss: 0.1354 | test acc: 95.55%\n",
      "test loss:  0.2518 | test acc:  92.02%\n",
      "\n",
      "Epoch 138/200\n",
      "train loss: 0.1298 | test acc: 95.69%\n",
      "test loss:  0.2379 | test acc:  92.44%\n",
      "\n",
      "Epoch 139/200\n",
      "train loss: 0.1370 | test acc: 95.42%\n",
      "test loss:  0.2731 | test acc:  91.72%\n",
      "\n",
      "Epoch 140/200\n",
      "train loss: 0.1439 | test acc: 95.29%\n",
      "test loss:  0.2367 | test acc:  92.19%\n",
      "checkpoint saved: checkpoints/train_4_20251119_115150/model_epoch_140.pt\n",
      "\n",
      "Epoch 141/200\n",
      "train loss: 0.1296 | test acc: 95.75%\n",
      "test loss:  0.2468 | test acc:  92.24%\n",
      "\n",
      "Epoch 142/200\n",
      "train loss: 0.1398 | test acc: 95.50%\n",
      "test loss:  0.2778 | test acc:  91.26%\n",
      "\n",
      "Epoch 143/200\n",
      "train loss: 0.1303 | test acc: 95.65%\n",
      "test loss:  0.2642 | test acc:  92.06%\n",
      "\n",
      "Epoch 144/200\n",
      "train loss: 0.1351 | test acc: 95.49%\n",
      "test loss:  0.2416 | test acc:  92.67%\n",
      "\n",
      "Epoch 145/200\n",
      "train loss: 0.1322 | test acc: 95.63%\n",
      "test loss:  0.2558 | test acc:  91.76%\n",
      "\n",
      "Epoch 146/200\n",
      "train loss: 0.1319 | test acc: 95.50%\n",
      "test loss:  0.2376 | test acc:  92.46%\n",
      "\n",
      "Epoch 147/200\n",
      "train loss: 0.1358 | test acc: 95.57%\n",
      "test loss:  0.2323 | test acc:  92.72%\n",
      "\n",
      "Epoch 148/200\n",
      "train loss: 0.1319 | test acc: 95.60%\n",
      "test loss:  0.2467 | test acc:  92.39%\n",
      "\n",
      "Epoch 149/200\n",
      "train loss: 0.1328 | test acc: 95.53%\n",
      "test loss:  0.2318 | test acc:  92.48%\n",
      "\n",
      "Epoch 150/200\n",
      "train loss: 0.1291 | test acc: 95.61%\n",
      "test loss:  0.2151 | test acc:  93.39%\n",
      "\n",
      "Epoch 151/200\n",
      "train loss: 0.1312 | test acc: 95.69%\n",
      "test loss:  0.2523 | test acc:  91.85%\n",
      "\n",
      "Epoch 152/200\n",
      "train loss: 0.1276 | test acc: 95.88%\n",
      "test loss:  0.2672 | test acc:  91.76%\n",
      "\n",
      "Epoch 153/200\n",
      "train loss: 0.1324 | test acc: 95.71%\n",
      "test loss:  0.2494 | test acc:  92.15%\n",
      "\n",
      "Epoch 154/200\n",
      "train loss: 0.1257 | test acc: 95.86%\n",
      "test loss:  0.2701 | test acc:  92.15%\n",
      "\n",
      "Epoch 155/200\n",
      "train loss: 0.1379 | test acc: 95.69%\n",
      "test loss:  0.2522 | test acc:  92.59%\n",
      "\n",
      "Epoch 156/200\n",
      "train loss: 0.1177 | test acc: 96.24%\n",
      "test loss:  0.2535 | test acc:  92.67%\n",
      "\n",
      "Epoch 157/200\n",
      "train loss: 0.1342 | test acc: 95.54%\n",
      "test loss:  0.2991 | test acc:  91.22%\n",
      "\n",
      "Epoch 158/200\n",
      "train loss: 0.1290 | test acc: 95.81%\n",
      "test loss:  0.2576 | test acc:  92.30%\n",
      "\n",
      "Epoch 159/200\n",
      "train loss: 0.1384 | test acc: 95.61%\n",
      "test loss:  0.2939 | test acc:  90.74%\n",
      "\n",
      "Epoch 160/200\n",
      "train loss: 0.1276 | test acc: 95.82%\n",
      "test loss:  0.2627 | test acc:  92.41%\n",
      "checkpoint saved: checkpoints/train_4_20251119_115150/model_epoch_160.pt\n",
      "\n",
      "Epoch 161/200\n",
      "train loss: 0.1263 | test acc: 95.89%\n",
      "test loss:  0.2570 | test acc:  92.61%\n",
      "\n",
      "Epoch 162/200\n",
      "train loss: 0.1312 | test acc: 95.88%\n",
      "test loss:  0.2645 | test acc:  92.33%\n",
      "\n",
      "Epoch 163/200\n",
      "train loss: 0.1326 | test acc: 95.66%\n",
      "test loss:  0.2481 | test acc:  92.41%\n",
      "\n",
      "Epoch 164/200\n",
      "train loss: 0.1175 | test acc: 96.13%\n",
      "test loss:  0.2675 | test acc:  91.78%\n",
      "\n",
      "Epoch 165/200\n",
      "train loss: 0.1237 | test acc: 96.02%\n",
      "test loss:  0.2297 | test acc:  92.85%\n",
      "\n",
      "Epoch 166/200\n",
      "train loss: 0.1293 | test acc: 95.80%\n",
      "test loss:  0.2459 | test acc:  92.89%\n",
      "\n",
      "Epoch 167/200\n",
      "train loss: 0.1250 | test acc: 95.81%\n",
      "test loss:  0.2442 | test acc:  92.72%\n",
      "\n",
      "Epoch 168/200\n",
      "train loss: 0.1323 | test acc: 95.67%\n",
      "test loss:  0.2415 | test acc:  92.39%\n",
      "\n",
      "Epoch 169/200\n",
      "train loss: 0.1272 | test acc: 95.85%\n",
      "test loss:  0.2551 | test acc:  91.96%\n",
      "\n",
      "Epoch 170/200\n",
      "train loss: 0.1136 | test acc: 96.32%\n",
      "test loss:  0.2442 | test acc:  92.91%\n",
      "\n",
      "Epoch 171/200\n",
      "train loss: 0.1281 | test acc: 95.93%\n",
      "test loss:  0.2405 | test acc:  92.31%\n",
      "\n",
      "Epoch 172/200\n",
      "train loss: 0.1266 | test acc: 95.89%\n",
      "test loss:  0.2544 | test acc:  92.20%\n",
      "\n",
      "Epoch 173/200\n",
      "train loss: 0.1198 | test acc: 96.16%\n",
      "test loss:  0.2484 | test acc:  92.81%\n",
      "\n",
      "Epoch 174/200\n",
      "train loss: 0.1190 | test acc: 95.99%\n",
      "test loss:  0.2350 | test acc:  92.80%\n",
      "\n",
      "Epoch 175/200\n",
      "train loss: 0.1140 | test acc: 96.15%\n",
      "test loss:  0.2359 | test acc:  92.48%\n",
      "\n",
      "Epoch 176/200\n",
      "train loss: 0.1173 | test acc: 96.23%\n",
      "test loss:  0.2668 | test acc:  91.96%\n",
      "\n",
      "Epoch 177/200\n",
      "train loss: 0.1150 | test acc: 96.21%\n",
      "test loss:  0.2256 | test acc:  93.31%\n",
      "\n",
      "Epoch 178/200\n",
      "train loss: 0.1218 | test acc: 95.98%\n",
      "test loss:  0.2367 | test acc:  92.44%\n",
      "\n",
      "Epoch 179/200\n",
      "train loss: 0.1222 | test acc: 95.95%\n",
      "test loss:  0.2371 | test acc:  92.74%\n",
      "\n",
      "Epoch 180/200\n",
      "train loss: 0.1234 | test acc: 96.06%\n",
      "test loss:  0.2551 | test acc:  92.43%\n",
      "checkpoint saved: checkpoints/train_4_20251119_115150/model_epoch_180.pt\n",
      "\n",
      "Epoch 181/200\n",
      "train loss: 0.1382 | test acc: 95.41%\n",
      "test loss:  0.2330 | test acc:  92.57%\n",
      "\n",
      "Epoch 182/200\n",
      "train loss: 0.1239 | test acc: 95.91%\n",
      "test loss:  0.2634 | test acc:  91.65%\n",
      "\n",
      "Epoch 183/200\n",
      "train loss: 0.1196 | test acc: 96.27%\n",
      "test loss:  0.2348 | test acc:  92.52%\n",
      "\n",
      "Epoch 184/200\n",
      "train loss: 0.1191 | test acc: 96.14%\n",
      "test loss:  0.2538 | test acc:  92.35%\n",
      "\n",
      "Epoch 185/200\n",
      "train loss: 0.1231 | test acc: 96.00%\n",
      "test loss:  0.2329 | test acc:  92.39%\n",
      "\n",
      "Epoch 186/200\n",
      "train loss: 0.1081 | test acc: 96.50%\n",
      "test loss:  0.2892 | test acc:  91.76%\n",
      "\n",
      "Epoch 187/200\n",
      "train loss: 0.1152 | test acc: 96.06%\n",
      "test loss:  0.2455 | test acc:  92.65%\n",
      "\n",
      "Epoch 188/200\n",
      "train loss: 0.1146 | test acc: 96.45%\n",
      "test loss:  0.2763 | test acc:  91.67%\n",
      "\n",
      "Epoch 189/200\n",
      "train loss: 0.1243 | test acc: 95.96%\n",
      "test loss:  0.2172 | test acc:  93.15%\n",
      "\n",
      "Epoch 190/200\n",
      "train loss: 0.1177 | test acc: 96.16%\n",
      "test loss:  0.2424 | test acc:  92.52%\n",
      "\n",
      "Epoch 191/200\n",
      "train loss: 0.1224 | test acc: 95.99%\n",
      "test loss:  0.2454 | test acc:  92.33%\n",
      "\n",
      "Epoch 192/200\n",
      "train loss: 0.1140 | test acc: 96.38%\n",
      "test loss:  0.2294 | test acc:  92.57%\n",
      "\n",
      "Epoch 193/200\n",
      "train loss: 0.1078 | test acc: 96.54%\n",
      "test loss:  0.2709 | test acc:  92.72%\n",
      "\n",
      "Epoch 194/200\n",
      "train loss: 0.1183 | test acc: 96.06%\n",
      "test loss:  0.2230 | test acc:  93.17%\n",
      "\n",
      "Epoch 195/200\n",
      "train loss: 0.1189 | test acc: 96.05%\n",
      "test loss:  0.2805 | test acc:  91.78%\n",
      "\n",
      "Epoch 196/200\n",
      "train loss: 0.1205 | test acc: 96.16%\n",
      "test loss:  0.2653 | test acc:  92.11%\n",
      "\n",
      "Epoch 197/200\n",
      "train loss: 0.1175 | test acc: 96.16%\n",
      "test loss:  0.2587 | test acc:  92.80%\n",
      "\n",
      "Epoch 198/200\n",
      "train loss: 0.1191 | test acc: 96.16%\n",
      "test loss:  0.2593 | test acc:  91.80%\n",
      "\n",
      "Epoch 199/200\n",
      "train loss: 0.1118 | test acc: 96.45%\n",
      "test loss:  0.2424 | test acc:  92.41%\n",
      "\n",
      "Epoch 200/200\n",
      "train loss: 0.1163 | test acc: 96.14%\n",
      "test loss:  0.2785 | test acc:  92.28%\n",
      "checkpoint saved: checkpoints/train_4_20251119_115150/model_epoch_200.pt\n",
      "\n",
      "final checkpoint saved: checkpoints/train_4_20251119_115150/model_final.pt\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "# tensorboard setup\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/train_{}_{}'.format(MODEL_NUMBER, timestamp))\n",
    "\n",
    "checkpoint_dir = f'checkpoints/train_{MODEL_NUMBER}_{timestamp}'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "EPOCHS = 200\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "    \n",
    "\n",
    "\n",
    "    train_loss, train_acc = train_one_epoch()\n",
    "    \n",
    "    test_loss, test_acc = test_one_epoch()\n",
    "    \n",
    "    print(f'train loss: {train_loss:.4f} | test acc: {train_acc:.2f}%')\n",
    "    print(f'test loss:  {test_loss:.4f} | test acc:  {test_acc:.2f}%')\n",
    "    \n",
    "    # log data\n",
    "    writer.add_scalar('loss/1_train', train_loss, epoch + 1)\n",
    "    writer.add_scalar('loss/2_test', test_loss, epoch + 1)\n",
    "    writer.add_scalar('accuracy/1_train', train_acc, epoch + 1)\n",
    "    writer.add_scalar('accuracy/2_test', test_acc, epoch + 1)\n",
    "    writer.flush()\n",
    "    \n",
    "    # checkpoint every 20 epochs\n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'model_epoch_{epoch + 1}.pt')\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "        print(f'checkpoint saved: {checkpoint_path}')\n",
    "    \n",
    "    print()\n",
    "\n",
    "# save final model\n",
    "final_checkpoint_path = os.path.join(checkpoint_dir, f'model_final.pt')\n",
    "torch.save(model.state_dict(), final_checkpoint_path)\n",
    "print(f'final checkpoint saved: {final_checkpoint_path}')\n",
    "\n",
    "writer.close()\n",
    "print('Complete')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
