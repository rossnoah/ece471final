{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42efbf30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 21600\n",
      "test size: 5400\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "MODEL_NUMBER = 2\n",
    "\n",
    "    \n",
    "# seed so random stuff isnt random\n",
    "SEED = 100\n",
    "\n",
    "# transforms\n",
    "transform = transforms.Compose([\n",
    "\n",
    "    transforms.RandomResizedCrop(64, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "dataset = torchvision.datasets.EuroSAT(root='./data', download=True, transform=transform)\n",
    "\n",
    "# split into train, test\n",
    "# 80% train, 20% test \n",
    "train_ratio = 0.8\n",
    "test_ratio = 0.2\n",
    "\n",
    "\n",
    "total_size = len(dataset)\n",
    "train_size = int(total_size * train_ratio)\n",
    "test_size = total_size - train_size\n",
    "\n",
    "\n",
    "train_dataset, test_dataset = random_split(\n",
    "    dataset, [train_size, test_size],\n",
    "    generator=torch.Generator().manual_seed(SEED)\n",
    ")\n",
    "\n",
    "print(f\"train: {len(train_dataset)}\")\n",
    "print(f\"test size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa92cd06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Model(\n",
      "  (relu): ReLU()\n",
      "  (c1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (c2): Conv2d(8, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout1): Dropout2d(p=0.25, inplace=False)\n",
      "  (c3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout2): Dropout2d(p=0.25, inplace=False)\n",
      "  (c5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout3): Dropout2d(p=0.25, inplace=False)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=8192, out_features=256, bias=True)\n",
      "  (dropout4): Dropout(p=0.5, inplace=False)\n",
      "  (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n",
      "Total parameters: 2287114\n"
     ]
    }
   ],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "        self.c1 = torch.nn.Conv2d(3, 8, 3, padding=1)\n",
    "        self.c2 = torch.nn.Conv2d(8, 32, 3, padding=1)\n",
    "        self.maxpool1 = torch.nn.MaxPool2d(2)\n",
    "        self.dropout1 = torch.nn.Dropout2d(0.25)\n",
    "        self.c3 = torch.nn.Conv2d(32, 128, 3, padding=1)\n",
    "        self.maxpool2 = torch.nn.MaxPool2d(2)\n",
    "        self.dropout2 = torch.nn.Dropout2d(0.25)\n",
    "        self.c5 = torch.nn.Conv2d(128, 128, 3, padding=1)\n",
    "        self.maxpool3 = torch.nn.MaxPool2d(2)\n",
    "        self.dropout3 = torch.nn.Dropout2d(0.25)\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.fc1 = torch.nn.Linear(128 * 8 * 8, 256)\n",
    "        self.dropout4 = torch.nn.Dropout(0.5)\n",
    "        self.fc2 = torch.nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.c1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.c2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.c3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.c5(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout4(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = Model()\n",
    "print(f\"Model: {model}\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters())}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "499a7ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# dataloaders\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=128, \n",
    "    shuffle=True,\n",
    "    pin_memory=True, # for use on gpu\n",
    "    num_workers=4 # arbitrarily chosen. some sources recommend 4 per gpu\n",
    ")\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=128, \n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b139e4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "if device == \"cuda\":\n",
    "    model.to(device, non_blocking=True) # according to pytorch docs we can do this if memory is pinned\n",
    "else:  \n",
    "    model.to(device)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "205d254c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch():\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def test_one_epoch():\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa66e8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "train loss: 1.8201 | test acc: 30.12%\n",
      "test loss:  1.4734 | test acc:  43.59%\n",
      "\n",
      "Epoch 2/200\n",
      "train loss: 1.3959 | test acc: 46.93%\n",
      "test loss:  1.1712 | test acc:  55.28%\n",
      "\n",
      "Epoch 3/200\n",
      "train loss: 1.2214 | test acc: 54.06%\n",
      "test loss:  1.0227 | test acc:  62.87%\n",
      "\n",
      "Epoch 4/200\n",
      "train loss: 1.1121 | test acc: 59.55%\n",
      "test loss:  0.9298 | test acc:  66.57%\n",
      "\n",
      "Epoch 5/200\n",
      "train loss: 1.0245 | test acc: 63.25%\n",
      "test loss:  0.8288 | test acc:  69.93%\n",
      "\n",
      "Epoch 6/200\n",
      "train loss: 0.9805 | test acc: 65.07%\n",
      "test loss:  0.8685 | test acc:  68.13%\n",
      "\n",
      "Epoch 7/200\n",
      "train loss: 0.9258 | test acc: 66.97%\n",
      "test loss:  0.7694 | test acc:  72.26%\n",
      "\n",
      "Epoch 8/200\n",
      "train loss: 0.8867 | test acc: 67.96%\n",
      "test loss:  0.7405 | test acc:  72.65%\n",
      "\n",
      "Epoch 9/200\n",
      "train loss: 0.8578 | test acc: 69.63%\n",
      "test loss:  0.7315 | test acc:  73.22%\n",
      "\n",
      "Epoch 10/200\n",
      "train loss: 0.8304 | test acc: 70.54%\n",
      "test loss:  0.6769 | test acc:  75.80%\n",
      "\n",
      "Epoch 11/200\n",
      "train loss: 0.8113 | test acc: 71.23%\n",
      "test loss:  0.6924 | test acc:  74.93%\n",
      "\n",
      "Epoch 12/200\n",
      "train loss: 0.7915 | test acc: 72.15%\n",
      "test loss:  0.6907 | test acc:  75.39%\n",
      "\n",
      "Epoch 13/200\n",
      "train loss: 0.7610 | test acc: 73.18%\n",
      "test loss:  0.6306 | test acc:  77.15%\n",
      "\n",
      "Epoch 14/200\n",
      "train loss: 0.7467 | test acc: 73.37%\n",
      "test loss:  0.6260 | test acc:  77.56%\n",
      "\n",
      "Epoch 15/200\n",
      "train loss: 0.7293 | test acc: 74.22%\n",
      "test loss:  0.6080 | test acc:  78.35%\n",
      "\n",
      "Epoch 16/200\n",
      "train loss: 0.7278 | test acc: 74.13%\n",
      "test loss:  0.6179 | test acc:  78.31%\n",
      "\n",
      "Epoch 17/200\n",
      "train loss: 0.7118 | test acc: 74.86%\n",
      "test loss:  0.5858 | test acc:  79.41%\n",
      "\n",
      "Epoch 18/200\n",
      "train loss: 0.6870 | test acc: 75.54%\n",
      "test loss:  0.5656 | test acc:  79.81%\n",
      "\n",
      "Epoch 19/200\n",
      "train loss: 0.6675 | test acc: 76.43%\n",
      "test loss:  0.5343 | test acc:  80.67%\n",
      "\n",
      "Epoch 20/200\n",
      "train loss: 0.6683 | test acc: 76.38%\n",
      "test loss:  0.5123 | test acc:  82.15%\n",
      "checkpoint saved: checkpoints/train_2_20251119_105725/model_epoch_20.pt\n",
      "\n",
      "Epoch 21/200\n",
      "train loss: 0.6469 | test acc: 76.87%\n",
      "test loss:  0.5228 | test acc:  81.61%\n",
      "\n",
      "Epoch 22/200\n",
      "train loss: 0.6493 | test acc: 77.12%\n",
      "test loss:  0.5217 | test acc:  81.80%\n",
      "\n",
      "Epoch 23/200\n",
      "train loss: 0.6372 | test acc: 77.78%\n",
      "test loss:  0.5110 | test acc:  81.98%\n",
      "\n",
      "Epoch 24/200\n",
      "train loss: 0.6200 | test acc: 78.40%\n",
      "test loss:  0.4831 | test acc:  83.13%\n",
      "\n",
      "Epoch 25/200\n",
      "train loss: 0.6200 | test acc: 78.93%\n",
      "test loss:  0.4899 | test acc:  82.98%\n",
      "\n",
      "Epoch 26/200\n",
      "train loss: 0.6059 | test acc: 78.69%\n",
      "test loss:  0.4960 | test acc:  82.28%\n",
      "\n",
      "Epoch 27/200\n",
      "train loss: 0.5975 | test acc: 79.28%\n",
      "test loss:  0.5088 | test acc:  82.04%\n",
      "\n",
      "Epoch 28/200\n",
      "train loss: 0.5919 | test acc: 79.25%\n",
      "test loss:  0.4936 | test acc:  82.98%\n",
      "\n",
      "Epoch 29/200\n",
      "train loss: 0.5858 | test acc: 79.67%\n",
      "test loss:  0.4601 | test acc:  84.35%\n",
      "\n",
      "Epoch 30/200\n",
      "train loss: 0.5787 | test acc: 80.19%\n",
      "test loss:  0.4762 | test acc:  82.93%\n",
      "\n",
      "Epoch 31/200\n",
      "train loss: 0.5666 | test acc: 80.57%\n",
      "test loss:  0.4577 | test acc:  83.87%\n",
      "\n",
      "Epoch 32/200\n",
      "train loss: 0.5635 | test acc: 80.42%\n",
      "test loss:  0.4351 | test acc:  84.50%\n",
      "\n",
      "Epoch 33/200\n",
      "train loss: 0.5529 | test acc: 80.94%\n",
      "test loss:  0.4543 | test acc:  83.87%\n",
      "\n",
      "Epoch 34/200\n",
      "train loss: 0.5573 | test acc: 80.59%\n",
      "test loss:  0.4274 | test acc:  84.52%\n",
      "\n",
      "Epoch 35/200\n",
      "train loss: 0.5396 | test acc: 81.34%\n",
      "test loss:  0.4120 | test acc:  85.30%\n",
      "\n",
      "Epoch 36/200\n",
      "train loss: 0.5399 | test acc: 81.20%\n",
      "test loss:  0.4320 | test acc:  85.00%\n",
      "\n",
      "Epoch 37/200\n",
      "train loss: 0.5283 | test acc: 81.90%\n",
      "test loss:  0.4228 | test acc:  85.07%\n",
      "\n",
      "Epoch 38/200\n",
      "train loss: 0.5294 | test acc: 81.46%\n",
      "test loss:  0.4057 | test acc:  85.52%\n",
      "\n",
      "Epoch 39/200\n",
      "train loss: 0.5207 | test acc: 82.29%\n",
      "test loss:  0.4131 | test acc:  85.41%\n",
      "\n",
      "Epoch 40/200\n",
      "train loss: 0.5288 | test acc: 81.74%\n",
      "test loss:  0.3905 | test acc:  86.07%\n",
      "checkpoint saved: checkpoints/train_2_20251119_105725/model_epoch_40.pt\n",
      "\n",
      "Epoch 41/200\n",
      "train loss: 0.5150 | test acc: 82.08%\n",
      "test loss:  0.3843 | test acc:  86.54%\n",
      "\n",
      "Epoch 42/200\n",
      "train loss: 0.5078 | test acc: 82.65%\n",
      "test loss:  0.3991 | test acc:  86.22%\n",
      "\n",
      "Epoch 43/200\n",
      "train loss: 0.5119 | test acc: 82.26%\n",
      "test loss:  0.3916 | test acc:  86.70%\n",
      "\n",
      "Epoch 44/200\n",
      "train loss: 0.4965 | test acc: 82.83%\n",
      "test loss:  0.3839 | test acc:  85.81%\n",
      "\n",
      "Epoch 45/200\n",
      "train loss: 0.4890 | test acc: 82.95%\n",
      "test loss:  0.3845 | test acc:  86.44%\n",
      "\n",
      "Epoch 46/200\n",
      "train loss: 0.5024 | test acc: 82.98%\n",
      "test loss:  0.4077 | test acc:  85.69%\n",
      "\n",
      "Epoch 47/200\n",
      "train loss: 0.4940 | test acc: 83.12%\n",
      "test loss:  0.3817 | test acc:  86.20%\n",
      "\n",
      "Epoch 48/200\n",
      "train loss: 0.4946 | test acc: 82.98%\n",
      "test loss:  0.3732 | test acc:  86.67%\n",
      "\n",
      "Epoch 49/200\n",
      "train loss: 0.4906 | test acc: 83.17%\n",
      "test loss:  0.3521 | test acc:  87.52%\n",
      "\n",
      "Epoch 50/200\n",
      "train loss: 0.4716 | test acc: 83.60%\n",
      "test loss:  0.3513 | test acc:  87.61%\n",
      "\n",
      "Epoch 51/200\n",
      "train loss: 0.4720 | test acc: 83.94%\n",
      "test loss:  0.3543 | test acc:  87.65%\n",
      "\n",
      "Epoch 52/200\n",
      "train loss: 0.4734 | test acc: 83.96%\n",
      "test loss:  0.3794 | test acc:  86.83%\n",
      "\n",
      "Epoch 53/200\n",
      "train loss: 0.4690 | test acc: 83.93%\n",
      "test loss:  0.3618 | test acc:  87.22%\n",
      "\n",
      "Epoch 54/200\n",
      "train loss: 0.4700 | test acc: 83.89%\n",
      "test loss:  0.3439 | test acc:  87.87%\n",
      "\n",
      "Epoch 55/200\n",
      "train loss: 0.4607 | test acc: 84.23%\n",
      "test loss:  0.3512 | test acc:  87.41%\n",
      "\n",
      "Epoch 56/200\n",
      "train loss: 0.4548 | test acc: 84.30%\n",
      "test loss:  0.3545 | test acc:  87.72%\n",
      "\n",
      "Epoch 57/200\n",
      "train loss: 0.4678 | test acc: 84.10%\n",
      "test loss:  0.3469 | test acc:  88.09%\n",
      "\n",
      "Epoch 58/200\n",
      "train loss: 0.4524 | test acc: 84.37%\n",
      "test loss:  0.3649 | test acc:  87.19%\n",
      "\n",
      "Epoch 59/200\n",
      "train loss: 0.4490 | test acc: 84.58%\n",
      "test loss:  0.3441 | test acc:  87.85%\n",
      "\n",
      "Epoch 60/200\n",
      "train loss: 0.4560 | test acc: 84.67%\n",
      "test loss:  0.3337 | test acc:  88.41%\n",
      "checkpoint saved: checkpoints/train_2_20251119_105725/model_epoch_60.pt\n",
      "\n",
      "Epoch 61/200\n",
      "train loss: 0.4498 | test acc: 84.86%\n",
      "test loss:  0.3322 | test acc:  88.07%\n",
      "\n",
      "Epoch 62/200\n",
      "train loss: 0.4446 | test acc: 84.95%\n",
      "test loss:  0.3520 | test acc:  87.67%\n",
      "\n",
      "Epoch 63/200\n",
      "train loss: 0.4398 | test acc: 84.91%\n",
      "test loss:  0.3398 | test acc:  87.96%\n",
      "\n",
      "Epoch 64/200\n",
      "train loss: 0.4420 | test acc: 84.73%\n",
      "test loss:  0.3261 | test acc:  88.63%\n",
      "\n",
      "Epoch 65/200\n",
      "train loss: 0.4354 | test acc: 85.21%\n",
      "test loss:  0.3386 | test acc:  88.48%\n",
      "\n",
      "Epoch 66/200\n",
      "train loss: 0.4346 | test acc: 85.27%\n",
      "test loss:  0.3229 | test acc:  88.43%\n",
      "\n",
      "Epoch 67/200\n",
      "train loss: 0.4319 | test acc: 85.20%\n",
      "test loss:  0.3043 | test acc:  89.15%\n",
      "\n",
      "Epoch 68/200\n",
      "train loss: 0.4204 | test acc: 85.41%\n",
      "test loss:  0.3165 | test acc:  89.20%\n",
      "\n",
      "Epoch 69/200\n",
      "train loss: 0.4261 | test acc: 85.52%\n",
      "test loss:  0.3081 | test acc:  89.17%\n",
      "\n",
      "Epoch 70/200\n",
      "train loss: 0.4224 | test acc: 85.80%\n",
      "test loss:  0.3294 | test acc:  88.50%\n",
      "\n",
      "Epoch 71/200\n",
      "train loss: 0.4310 | test acc: 85.22%\n",
      "test loss:  0.3352 | test acc:  88.00%\n",
      "\n",
      "Epoch 72/200\n",
      "train loss: 0.4186 | test acc: 85.65%\n",
      "test loss:  0.3465 | test acc:  88.20%\n",
      "\n",
      "Epoch 73/200\n",
      "train loss: 0.4123 | test acc: 86.18%\n",
      "test loss:  0.3434 | test acc:  88.52%\n",
      "\n",
      "Epoch 74/200\n",
      "train loss: 0.4170 | test acc: 85.85%\n",
      "test loss:  0.3153 | test acc:  89.04%\n",
      "\n",
      "Epoch 75/200\n",
      "train loss: 0.4141 | test acc: 85.79%\n",
      "test loss:  0.3172 | test acc:  88.91%\n",
      "\n",
      "Epoch 76/200\n",
      "train loss: 0.4107 | test acc: 85.95%\n",
      "test loss:  0.3293 | test acc:  88.43%\n",
      "\n",
      "Epoch 77/200\n",
      "train loss: 0.4049 | test acc: 86.31%\n",
      "test loss:  0.3019 | test acc:  89.67%\n",
      "\n",
      "Epoch 78/200\n",
      "train loss: 0.4179 | test acc: 85.97%\n",
      "test loss:  0.2953 | test acc:  89.74%\n",
      "\n",
      "Epoch 79/200\n",
      "train loss: 0.3994 | test acc: 86.41%\n",
      "test loss:  0.2989 | test acc:  89.87%\n",
      "\n",
      "Epoch 80/200\n",
      "train loss: 0.3956 | test acc: 86.54%\n",
      "test loss:  0.2930 | test acc:  90.31%\n",
      "checkpoint saved: checkpoints/train_2_20251119_105725/model_epoch_80.pt\n",
      "\n",
      "Epoch 81/200\n",
      "train loss: 0.4070 | test acc: 86.10%\n",
      "test loss:  0.3461 | test acc:  88.11%\n",
      "\n",
      "Epoch 82/200\n",
      "train loss: 0.4031 | test acc: 86.22%\n",
      "test loss:  0.3033 | test acc:  89.26%\n",
      "\n",
      "Epoch 83/200\n",
      "train loss: 0.3982 | test acc: 86.46%\n",
      "test loss:  0.3010 | test acc:  89.35%\n",
      "\n",
      "Epoch 84/200\n",
      "train loss: 0.3953 | test acc: 86.61%\n",
      "test loss:  0.2893 | test acc:  89.85%\n",
      "\n",
      "Epoch 85/200\n",
      "train loss: 0.4012 | test acc: 86.48%\n",
      "test loss:  0.3054 | test acc:  89.46%\n",
      "\n",
      "Epoch 86/200\n",
      "train loss: 0.3965 | test acc: 86.66%\n",
      "test loss:  0.2965 | test acc:  89.74%\n",
      "\n",
      "Epoch 87/200\n",
      "train loss: 0.3936 | test acc: 86.49%\n",
      "test loss:  0.3082 | test acc:  89.52%\n",
      "\n",
      "Epoch 88/200\n",
      "train loss: 0.3998 | test acc: 86.40%\n",
      "test loss:  0.3197 | test acc:  88.98%\n",
      "\n",
      "Epoch 89/200\n",
      "train loss: 0.3812 | test acc: 86.82%\n",
      "test loss:  0.3047 | test acc:  89.22%\n",
      "\n",
      "Epoch 90/200\n",
      "train loss: 0.3855 | test acc: 86.74%\n",
      "test loss:  0.3066 | test acc:  88.94%\n",
      "\n",
      "Epoch 91/200\n",
      "train loss: 0.3934 | test acc: 86.88%\n",
      "test loss:  0.3014 | test acc:  89.33%\n",
      "\n",
      "Epoch 92/200\n",
      "train loss: 0.3875 | test acc: 86.72%\n",
      "test loss:  0.2780 | test acc:  90.30%\n",
      "\n",
      "Epoch 93/200\n",
      "train loss: 0.3886 | test acc: 86.71%\n",
      "test loss:  0.2956 | test acc:  89.80%\n",
      "\n",
      "Epoch 94/200\n",
      "train loss: 0.3875 | test acc: 86.63%\n",
      "test loss:  0.2946 | test acc:  89.98%\n",
      "\n",
      "Epoch 95/200\n",
      "train loss: 0.3859 | test acc: 87.01%\n",
      "test loss:  0.2828 | test acc:  90.33%\n",
      "\n",
      "Epoch 96/200\n",
      "train loss: 0.3850 | test acc: 86.80%\n",
      "test loss:  0.2816 | test acc:  89.96%\n",
      "\n",
      "Epoch 97/200\n",
      "train loss: 0.3806 | test acc: 86.83%\n",
      "test loss:  0.3182 | test acc:  89.02%\n",
      "\n",
      "Epoch 98/200\n",
      "train loss: 0.3704 | test acc: 87.36%\n",
      "test loss:  0.2680 | test acc:  90.87%\n",
      "\n",
      "Epoch 99/200\n",
      "train loss: 0.3861 | test acc: 87.05%\n",
      "test loss:  0.2804 | test acc:  90.43%\n",
      "\n",
      "Epoch 100/200\n",
      "train loss: 0.3747 | test acc: 87.28%\n",
      "test loss:  0.2684 | test acc:  90.76%\n",
      "checkpoint saved: checkpoints/train_2_20251119_105725/model_epoch_100.pt\n",
      "\n",
      "Epoch 101/200\n",
      "train loss: 0.3714 | test acc: 87.31%\n",
      "test loss:  0.3054 | test acc:  89.24%\n",
      "\n",
      "Epoch 102/200\n",
      "train loss: 0.3771 | test acc: 87.19%\n",
      "test loss:  0.2930 | test acc:  89.67%\n",
      "\n",
      "Epoch 103/200\n",
      "train loss: 0.3714 | test acc: 87.34%\n",
      "test loss:  0.3088 | test acc:  89.39%\n",
      "\n",
      "Epoch 104/200\n",
      "train loss: 0.3716 | test acc: 87.48%\n",
      "test loss:  0.2734 | test acc:  90.65%\n",
      "\n",
      "Epoch 105/200\n",
      "train loss: 0.3617 | test acc: 87.65%\n",
      "test loss:  0.2910 | test acc:  89.76%\n",
      "\n",
      "Epoch 106/200\n",
      "train loss: 0.3704 | test acc: 87.60%\n",
      "test loss:  0.2883 | test acc:  90.02%\n",
      "\n",
      "Epoch 107/200\n",
      "train loss: 0.3741 | test acc: 87.20%\n",
      "test loss:  0.3002 | test acc:  89.48%\n",
      "\n",
      "Epoch 108/200\n",
      "train loss: 0.3642 | test acc: 87.45%\n",
      "test loss:  0.2817 | test acc:  89.87%\n",
      "\n",
      "Epoch 109/200\n",
      "train loss: 0.3676 | test acc: 87.70%\n",
      "test loss:  0.2715 | test acc:  90.69%\n",
      "\n",
      "Epoch 110/200\n",
      "train loss: 0.3631 | test acc: 87.68%\n",
      "test loss:  0.3057 | test acc:  89.81%\n",
      "\n",
      "Epoch 111/200\n",
      "train loss: 0.3726 | test acc: 87.44%\n",
      "test loss:  0.3084 | test acc:  89.17%\n",
      "\n",
      "Epoch 112/200\n",
      "train loss: 0.3812 | test acc: 87.17%\n",
      "test loss:  0.2799 | test acc:  90.59%\n",
      "\n",
      "Epoch 113/200\n",
      "train loss: 0.3559 | test acc: 88.18%\n",
      "test loss:  0.2766 | test acc:  90.63%\n",
      "\n",
      "Epoch 114/200\n",
      "train loss: 0.3656 | test acc: 87.49%\n",
      "test loss:  0.2871 | test acc:  89.67%\n",
      "\n",
      "Epoch 115/200\n",
      "train loss: 0.3628 | test acc: 87.73%\n",
      "test loss:  0.2881 | test acc:  89.98%\n",
      "\n",
      "Epoch 116/200\n",
      "train loss: 0.3521 | test acc: 87.77%\n",
      "test loss:  0.2896 | test acc:  89.56%\n",
      "\n",
      "Epoch 117/200\n",
      "train loss: 0.3670 | test acc: 87.62%\n",
      "test loss:  0.2632 | test acc:  90.96%\n",
      "\n",
      "Epoch 118/200\n",
      "train loss: 0.3609 | test acc: 87.62%\n",
      "test loss:  0.2732 | test acc:  90.22%\n",
      "\n",
      "Epoch 119/200\n",
      "train loss: 0.3543 | test acc: 87.88%\n",
      "test loss:  0.2693 | test acc:  90.78%\n",
      "\n",
      "Epoch 120/200\n",
      "train loss: 0.3575 | test acc: 87.63%\n",
      "test loss:  0.2751 | test acc:  90.33%\n",
      "checkpoint saved: checkpoints/train_2_20251119_105725/model_epoch_120.pt\n",
      "\n",
      "Epoch 121/200\n",
      "train loss: 0.3565 | test acc: 87.84%\n",
      "test loss:  0.2883 | test acc:  90.04%\n",
      "\n",
      "Epoch 122/200\n",
      "train loss: 0.3589 | test acc: 87.90%\n",
      "test loss:  0.2934 | test acc:  89.43%\n",
      "\n",
      "Epoch 123/200\n",
      "train loss: 0.3581 | test acc: 87.72%\n",
      "test loss:  0.2771 | test acc:  90.35%\n",
      "\n",
      "Epoch 124/200\n",
      "train loss: 0.3497 | test acc: 87.94%\n",
      "test loss:  0.2837 | test acc:  90.28%\n",
      "\n",
      "Epoch 125/200\n",
      "train loss: 0.3559 | test acc: 88.02%\n",
      "test loss:  0.2734 | test acc:  90.67%\n",
      "\n",
      "Epoch 126/200\n",
      "train loss: 0.3576 | test acc: 87.94%\n",
      "test loss:  0.2798 | test acc:  90.44%\n",
      "\n",
      "Epoch 127/200\n",
      "train loss: 0.3481 | test acc: 88.38%\n",
      "test loss:  0.2915 | test acc:  89.61%\n",
      "\n",
      "Epoch 128/200\n",
      "train loss: 0.3511 | test acc: 87.84%\n",
      "test loss:  0.2650 | test acc:  90.96%\n",
      "\n",
      "Epoch 129/200\n",
      "train loss: 0.3458 | test acc: 88.09%\n",
      "test loss:  0.2732 | test acc:  90.54%\n",
      "\n",
      "Epoch 130/200\n",
      "train loss: 0.3566 | test acc: 87.87%\n",
      "test loss:  0.2636 | test acc:  91.17%\n",
      "\n",
      "Epoch 131/200\n",
      "train loss: 0.3567 | test acc: 87.90%\n",
      "test loss:  0.2715 | test acc:  90.22%\n",
      "\n",
      "Epoch 132/200\n",
      "train loss: 0.3445 | test acc: 88.35%\n",
      "test loss:  0.2668 | test acc:  90.37%\n",
      "\n",
      "Epoch 133/200\n",
      "train loss: 0.3500 | test acc: 88.02%\n",
      "test loss:  0.2608 | test acc:  90.74%\n",
      "\n",
      "Epoch 134/200\n",
      "train loss: 0.3395 | test acc: 88.45%\n",
      "test loss:  0.2599 | test acc:  90.83%\n",
      "\n",
      "Epoch 135/200\n",
      "train loss: 0.3376 | test acc: 88.68%\n",
      "test loss:  0.2818 | test acc:  90.24%\n",
      "\n",
      "Epoch 136/200\n",
      "train loss: 0.3509 | test acc: 88.00%\n",
      "test loss:  0.2708 | test acc:  90.59%\n",
      "\n",
      "Epoch 137/200\n",
      "train loss: 0.3464 | test acc: 88.16%\n",
      "test loss:  0.2557 | test acc:  91.13%\n",
      "\n",
      "Epoch 138/200\n",
      "train loss: 0.3428 | test acc: 88.23%\n",
      "test loss:  0.2517 | test acc:  91.02%\n",
      "\n",
      "Epoch 139/200\n",
      "train loss: 0.3360 | test acc: 88.50%\n",
      "test loss:  0.2671 | test acc:  90.69%\n",
      "\n",
      "Epoch 140/200\n",
      "train loss: 0.3439 | test acc: 88.36%\n",
      "test loss:  0.2812 | test acc:  89.81%\n",
      "checkpoint saved: checkpoints/train_2_20251119_105725/model_epoch_140.pt\n",
      "\n",
      "Epoch 141/200\n",
      "train loss: 0.3327 | test acc: 88.80%\n",
      "test loss:  0.2650 | test acc:  90.70%\n",
      "\n",
      "Epoch 142/200\n",
      "train loss: 0.3454 | test acc: 88.21%\n",
      "test loss:  0.2681 | test acc:  91.13%\n",
      "\n",
      "Epoch 143/200\n",
      "train loss: 0.3452 | test acc: 88.16%\n",
      "test loss:  0.2686 | test acc:  90.69%\n",
      "\n",
      "Epoch 144/200\n",
      "train loss: 0.3359 | test acc: 88.62%\n",
      "test loss:  0.2584 | test acc:  91.07%\n",
      "\n",
      "Epoch 145/200\n",
      "train loss: 0.3303 | test acc: 88.50%\n",
      "test loss:  0.2815 | test acc:  90.11%\n",
      "\n",
      "Epoch 146/200\n",
      "train loss: 0.3379 | test acc: 88.63%\n",
      "test loss:  0.2720 | test acc:  90.37%\n",
      "\n",
      "Epoch 147/200\n",
      "train loss: 0.3500 | test acc: 87.84%\n",
      "test loss:  0.2657 | test acc:  90.94%\n",
      "\n",
      "Epoch 148/200\n",
      "train loss: 0.3403 | test acc: 88.55%\n",
      "test loss:  0.2636 | test acc:  90.81%\n",
      "\n",
      "Epoch 149/200\n",
      "train loss: 0.3355 | test acc: 88.59%\n",
      "test loss:  0.2696 | test acc:  90.69%\n",
      "\n",
      "Epoch 150/200\n",
      "train loss: 0.3261 | test acc: 88.86%\n",
      "test loss:  0.2681 | test acc:  90.67%\n",
      "\n",
      "Epoch 151/200\n",
      "train loss: 0.3341 | test acc: 88.53%\n",
      "test loss:  0.2622 | test acc:  91.22%\n",
      "\n",
      "Epoch 152/200\n",
      "train loss: 0.3283 | test acc: 88.94%\n",
      "test loss:  0.2651 | test acc:  90.89%\n",
      "\n",
      "Epoch 153/200\n",
      "train loss: 0.3281 | test acc: 88.78%\n",
      "test loss:  0.2588 | test acc:  91.02%\n",
      "\n",
      "Epoch 154/200\n",
      "train loss: 0.3245 | test acc: 89.04%\n",
      "test loss:  0.2503 | test acc:  91.02%\n",
      "\n",
      "Epoch 155/200\n",
      "train loss: 0.3400 | test acc: 88.60%\n",
      "test loss:  0.2724 | test acc:  90.69%\n",
      "\n",
      "Epoch 156/200\n",
      "train loss: 0.3282 | test acc: 89.01%\n",
      "test loss:  0.2686 | test acc:  90.69%\n",
      "\n",
      "Epoch 157/200\n",
      "train loss: 0.3329 | test acc: 88.61%\n",
      "test loss:  0.2573 | test acc:  91.31%\n",
      "\n",
      "Epoch 158/200\n",
      "train loss: 0.3223 | test acc: 88.89%\n",
      "test loss:  0.2490 | test acc:  91.20%\n",
      "\n",
      "Epoch 159/200\n",
      "train loss: 0.3365 | test acc: 88.59%\n",
      "test loss:  0.2754 | test acc:  90.63%\n",
      "\n",
      "Epoch 160/200\n",
      "train loss: 0.3302 | test acc: 88.85%\n",
      "test loss:  0.2758 | test acc:  90.09%\n",
      "checkpoint saved: checkpoints/train_2_20251119_105725/model_epoch_160.pt\n",
      "\n",
      "Epoch 161/200\n",
      "train loss: 0.3297 | test acc: 88.81%\n",
      "test loss:  0.2498 | test acc:  91.44%\n",
      "\n",
      "Epoch 162/200\n",
      "train loss: 0.3321 | test acc: 88.64%\n",
      "test loss:  0.2632 | test acc:  90.89%\n",
      "\n",
      "Epoch 163/200\n",
      "train loss: 0.3327 | test acc: 88.44%\n",
      "test loss:  0.2496 | test acc:  91.33%\n",
      "\n",
      "Epoch 164/200\n",
      "train loss: 0.3242 | test acc: 89.03%\n",
      "test loss:  0.2566 | test acc:  90.93%\n",
      "\n",
      "Epoch 165/200\n",
      "train loss: 0.3253 | test acc: 88.95%\n",
      "test loss:  0.2616 | test acc:  91.02%\n",
      "\n",
      "Epoch 166/200\n",
      "train loss: 0.3248 | test acc: 88.99%\n",
      "test loss:  0.2571 | test acc:  90.89%\n",
      "\n",
      "Epoch 167/200\n",
      "train loss: 0.3282 | test acc: 88.61%\n",
      "test loss:  0.2373 | test acc:  91.54%\n",
      "\n",
      "Epoch 168/200\n",
      "train loss: 0.3296 | test acc: 88.65%\n",
      "test loss:  0.2454 | test acc:  91.22%\n",
      "\n",
      "Epoch 169/200\n",
      "train loss: 0.3219 | test acc: 89.02%\n",
      "test loss:  0.2629 | test acc:  90.83%\n",
      "\n",
      "Epoch 170/200\n",
      "train loss: 0.3254 | test acc: 88.84%\n",
      "test loss:  0.2542 | test acc:  91.44%\n",
      "\n",
      "Epoch 171/200\n",
      "train loss: 0.3357 | test acc: 88.79%\n",
      "test loss:  0.2575 | test acc:  91.28%\n",
      "\n",
      "Epoch 172/200\n",
      "train loss: 0.3217 | test acc: 89.05%\n",
      "test loss:  0.2454 | test acc:  91.59%\n",
      "\n",
      "Epoch 173/200\n",
      "train loss: 0.3248 | test acc: 88.97%\n",
      "test loss:  0.2572 | test acc:  91.24%\n",
      "\n",
      "Epoch 174/200\n",
      "train loss: 0.3210 | test acc: 88.84%\n",
      "test loss:  0.2540 | test acc:  91.00%\n",
      "\n",
      "Epoch 175/200\n",
      "train loss: 0.3212 | test acc: 89.00%\n",
      "test loss:  0.2384 | test acc:  91.61%\n",
      "\n",
      "Epoch 176/200\n",
      "train loss: 0.3197 | test acc: 89.17%\n",
      "test loss:  0.2499 | test acc:  91.20%\n",
      "\n",
      "Epoch 177/200\n",
      "train loss: 0.3071 | test acc: 89.31%\n",
      "test loss:  0.2391 | test acc:  91.54%\n",
      "\n",
      "Epoch 178/200\n",
      "train loss: 0.3210 | test acc: 89.01%\n",
      "test loss:  0.2560 | test acc:  91.22%\n",
      "\n",
      "Epoch 179/200\n",
      "train loss: 0.3188 | test acc: 89.02%\n",
      "test loss:  0.2500 | test acc:  91.39%\n",
      "\n",
      "Epoch 180/200\n",
      "train loss: 0.3229 | test acc: 88.94%\n",
      "test loss:  0.2636 | test acc:  90.91%\n",
      "checkpoint saved: checkpoints/train_2_20251119_105725/model_epoch_180.pt\n",
      "\n",
      "Epoch 181/200\n",
      "train loss: 0.3167 | test acc: 89.16%\n",
      "test loss:  0.2376 | test acc:  91.61%\n",
      "\n",
      "Epoch 182/200\n",
      "train loss: 0.3184 | test acc: 89.25%\n",
      "test loss:  0.2652 | test acc:  90.43%\n",
      "\n",
      "Epoch 183/200\n",
      "train loss: 0.3348 | test acc: 88.82%\n",
      "test loss:  0.2429 | test acc:  91.15%\n",
      "\n",
      "Epoch 184/200\n",
      "train loss: 0.3186 | test acc: 89.13%\n",
      "test loss:  0.2446 | test acc:  91.15%\n",
      "\n",
      "Epoch 185/200\n",
      "train loss: 0.3127 | test acc: 89.22%\n",
      "test loss:  0.2617 | test acc:  90.69%\n",
      "\n",
      "Epoch 186/200\n",
      "train loss: 0.3259 | test acc: 88.78%\n",
      "test loss:  0.2445 | test acc:  91.37%\n",
      "\n",
      "Epoch 187/200\n",
      "train loss: 0.3183 | test acc: 89.06%\n",
      "test loss:  0.2652 | test acc:  91.11%\n",
      "\n",
      "Epoch 188/200\n",
      "train loss: 0.3213 | test acc: 88.98%\n",
      "test loss:  0.2478 | test acc:  91.22%\n",
      "\n",
      "Epoch 189/200\n",
      "train loss: 0.3123 | test acc: 89.37%\n",
      "test loss:  0.2690 | test acc:  91.00%\n",
      "\n",
      "Epoch 190/200\n",
      "train loss: 0.3239 | test acc: 88.96%\n",
      "test loss:  0.2737 | test acc:  90.48%\n",
      "\n",
      "Epoch 191/200\n",
      "train loss: 0.3180 | test acc: 89.35%\n",
      "test loss:  0.2527 | test acc:  91.22%\n",
      "\n",
      "Epoch 192/200\n",
      "train loss: 0.3014 | test acc: 89.83%\n",
      "test loss:  0.2485 | test acc:  91.35%\n",
      "\n",
      "Epoch 193/200\n",
      "train loss: 0.3272 | test acc: 89.13%\n",
      "test loss:  0.2447 | test acc:  91.57%\n",
      "\n",
      "Epoch 194/200\n",
      "train loss: 0.3079 | test acc: 89.77%\n",
      "test loss:  0.2618 | test acc:  91.44%\n",
      "\n",
      "Epoch 195/200\n",
      "train loss: 0.3050 | test acc: 89.57%\n",
      "test loss:  0.2438 | test acc:  91.35%\n",
      "\n",
      "Epoch 196/200\n",
      "train loss: 0.3128 | test acc: 89.31%\n",
      "test loss:  0.2672 | test acc:  90.57%\n",
      "\n",
      "Epoch 197/200\n",
      "train loss: 0.3192 | test acc: 89.27%\n",
      "test loss:  0.2519 | test acc:  91.28%\n",
      "\n",
      "Epoch 198/200\n",
      "train loss: 0.3098 | test acc: 89.48%\n",
      "test loss:  0.2406 | test acc:  91.56%\n",
      "\n",
      "Epoch 199/200\n",
      "train loss: 0.3120 | test acc: 89.28%\n",
      "test loss:  0.2313 | test acc:  92.09%\n",
      "\n",
      "Epoch 200/200\n",
      "train loss: 0.3185 | test acc: 88.89%\n",
      "test loss:  0.2669 | test acc:  90.83%\n",
      "checkpoint saved: checkpoints/train_2_20251119_105725/model_epoch_200.pt\n",
      "\n",
      "final checkpoint saved: checkpoints/train_2_20251119_105725/model_final.pt\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "# tensorboard setup\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/train_{}_{}'.format(MODEL_NUMBER, timestamp))\n",
    "\n",
    "checkpoint_dir = f'checkpoints/train_{MODEL_NUMBER}_{timestamp}'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "EPOCHS = 200\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "    \n",
    "\n",
    "\n",
    "    train_loss, train_acc = train_one_epoch()\n",
    "    \n",
    "    test_loss, test_acc = test_one_epoch()\n",
    "    \n",
    "    print(f'train loss: {train_loss:.4f} | test acc: {train_acc:.2f}%')\n",
    "    print(f'test loss:  {test_loss:.4f} | test acc:  {test_acc:.2f}%')\n",
    "    \n",
    "    # log data\n",
    "    writer.add_scalar('loss/1_train', train_loss, epoch + 1)\n",
    "    writer.add_scalar('loss/2_test', test_loss, epoch + 1)\n",
    "    writer.add_scalar('accuracy/1_train', train_acc, epoch + 1)\n",
    "    writer.add_scalar('accuracy/2_test', test_acc, epoch + 1)\n",
    "    writer.flush()\n",
    "    \n",
    "    # checkpoint every 20 epochs\n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'model_epoch_{epoch + 1}.pt')\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "        print(f'checkpoint saved: {checkpoint_path}')\n",
    "    \n",
    "    print()\n",
    "\n",
    "# save final model\n",
    "final_checkpoint_path = os.path.join(checkpoint_dir, f'model_final.pt')\n",
    "torch.save(model.state_dict(), final_checkpoint_path)\n",
    "print(f'final checkpoint saved: {final_checkpoint_path}')\n",
    "\n",
    "writer.close()\n",
    "print('Complete')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
