{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "42efbf30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 21600\n",
      "test size: 5400\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# seed so random stuff isnt random\n",
    "SEED = 100\n",
    "\n",
    "# transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "dataset = torchvision.datasets.EuroSAT(root='./data', download=True, transform=transform)\n",
    "\n",
    "# split into train, test\n",
    "# 80% train, 20% test \n",
    "train_ratio = 0.8\n",
    "test_ratio = 0.2\n",
    "\n",
    "\n",
    "total_size = len(dataset)\n",
    "train_size = int(total_size * train_ratio)\n",
    "test_size = total_size - train_size\n",
    "\n",
    "\n",
    "train_dataset, test_dataset = random_split(\n",
    "    dataset, [train_size, test_size],\n",
    "    generator=torch.Generator().manual_seed(SEED)\n",
    ")\n",
    "\n",
    "print(f\"train: {len(train_dataset)}\")\n",
    "print(f\"test size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "aa92cd06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Model(\n",
      "  (relu): ReLU()\n",
      "  (c1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (c2): Conv2d(8, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (c3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (c5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=8192, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n",
      "Total parameters: 2287114\n"
     ]
    }
   ],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "        self.c1 = torch.nn.Conv2d(3, 8, 3, padding=1)\n",
    "        self.c2 = torch.nn.Conv2d(8, 32, 3, padding=1)\n",
    "        self.maxpool1 = torch.nn.MaxPool2d(2)\n",
    "        self.c3 = torch.nn.Conv2d(32, 128, 3, padding=1)\n",
    "        self.maxpool2 = torch.nn.MaxPool2d(2)\n",
    "        self.c5 = torch.nn.Conv2d(128, 128, 3, padding=1)\n",
    "        self.maxpool3 = torch.nn.MaxPool2d(2)\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.fc1 = torch.nn.Linear(128 * 8 * 8, 256)\n",
    "        self.fc2 = torch.nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.c1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.c2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.c3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.c5(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool3(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = Model()\n",
    "print(f\"Model: {model}\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters())}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "499a7ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# dataloaders\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=128, \n",
    "    shuffle=True,\n",
    "    pin_memory=True, # for use on gpu\n",
    "    num_workers=4 # arbitrarily chosen. some sources recommend 4 per gpu\n",
    ")\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=128, \n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b139e4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "if device == \"cuda\":\n",
    "    model.to(device, non_blocking=True) # according to pytorch docs we can do this if memory is pinned\n",
    "else:  \n",
    "    model.to(device)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "205d254c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch():\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def test_one_epoch():\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "aa66e8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "train loss: 1.5158 | test acc: 42.65%\n",
      "test loss:  1.2693 | test acc:  55.72%\n",
      "\n",
      "Epoch 2/100\n",
      "train loss: 0.9551 | test acc: 64.98%\n",
      "test loss:  0.8742 | test acc:  67.72%\n",
      "\n",
      "Epoch 3/100\n",
      "train loss: 0.7326 | test acc: 73.70%\n",
      "test loss:  0.7111 | test acc:  74.30%\n",
      "\n",
      "Epoch 4/100\n",
      "train loss: 0.6105 | test acc: 78.05%\n",
      "test loss:  0.5479 | test acc:  80.02%\n",
      "\n",
      "Epoch 5/100\n",
      "train loss: 0.5200 | test acc: 81.17%\n",
      "test loss:  0.5259 | test acc:  81.24%\n",
      "\n",
      "Epoch 6/100\n",
      "train loss: 0.4718 | test acc: 83.34%\n",
      "test loss:  0.5272 | test acc:  81.11%\n",
      "\n",
      "Epoch 7/100\n",
      "train loss: 0.4347 | test acc: 84.38%\n",
      "test loss:  0.4940 | test acc:  82.65%\n",
      "\n",
      "Epoch 8/100\n",
      "train loss: 0.3917 | test acc: 86.08%\n",
      "test loss:  0.5671 | test acc:  80.22%\n",
      "\n",
      "Epoch 9/100\n",
      "train loss: 0.3500 | test acc: 87.59%\n",
      "test loss:  0.5962 | test acc:  78.57%\n",
      "\n",
      "Epoch 10/100\n",
      "train loss: 0.3161 | test acc: 88.69%\n",
      "test loss:  0.4231 | test acc:  85.13%\n",
      "\n",
      "Epoch 11/100\n",
      "train loss: 0.2724 | test acc: 90.32%\n",
      "test loss:  0.4757 | test acc:  84.02%\n",
      "\n",
      "Epoch 12/100\n",
      "train loss: 0.2388 | test acc: 91.73%\n",
      "test loss:  0.3964 | test acc:  85.70%\n",
      "\n",
      "Epoch 13/100\n",
      "train loss: 0.2193 | test acc: 92.54%\n",
      "test loss:  0.4525 | test acc:  84.63%\n",
      "\n",
      "Epoch 14/100\n",
      "train loss: 0.1912 | test acc: 93.40%\n",
      "test loss:  0.4572 | test acc:  85.87%\n",
      "\n",
      "Epoch 15/100\n",
      "train loss: 0.1505 | test acc: 94.81%\n",
      "test loss:  0.4646 | test acc:  85.37%\n",
      "\n",
      "Epoch 16/100\n",
      "train loss: 0.1199 | test acc: 95.88%\n",
      "test loss:  0.4706 | test acc:  85.67%\n",
      "\n",
      "Epoch 17/100\n",
      "train loss: 0.1115 | test acc: 96.24%\n",
      "test loss:  0.4968 | test acc:  86.37%\n",
      "\n",
      "Epoch 18/100\n",
      "train loss: 0.1042 | test acc: 96.39%\n",
      "test loss:  0.4949 | test acc:  86.85%\n",
      "\n",
      "Epoch 19/100\n",
      "train loss: 0.0965 | test acc: 96.70%\n",
      "test loss:  0.6097 | test acc:  84.26%\n",
      "\n",
      "Epoch 20/100\n",
      "train loss: 0.0736 | test acc: 97.63%\n",
      "test loss:  0.5422 | test acc:  85.78%\n",
      "checkpoint saved: checkpoints/train_1_20251119_103843/model_epoch_20.pt\n",
      "\n",
      "Epoch 21/100\n",
      "train loss: 0.0532 | test acc: 98.35%\n",
      "test loss:  0.5956 | test acc:  85.94%\n",
      "\n",
      "Epoch 22/100\n",
      "train loss: 0.0519 | test acc: 98.26%\n",
      "test loss:  0.5993 | test acc:  86.00%\n",
      "\n",
      "Epoch 23/100\n",
      "train loss: 0.0438 | test acc: 98.54%\n",
      "test loss:  0.5861 | test acc:  86.69%\n",
      "\n",
      "Epoch 24/100\n",
      "train loss: 0.0401 | test acc: 98.68%\n",
      "test loss:  0.6639 | test acc:  85.78%\n",
      "\n",
      "Epoch 25/100\n",
      "train loss: 0.0765 | test acc: 97.41%\n",
      "test loss:  0.6435 | test acc:  85.61%\n",
      "\n",
      "Epoch 26/100\n",
      "train loss: 0.0365 | test acc: 98.83%\n",
      "test loss:  0.7163 | test acc:  85.22%\n",
      "\n",
      "Epoch 27/100\n",
      "train loss: 0.0360 | test acc: 98.81%\n",
      "test loss:  0.7242 | test acc:  85.91%\n",
      "\n",
      "Epoch 28/100\n",
      "train loss: 0.0397 | test acc: 98.61%\n",
      "test loss:  0.7483 | test acc:  84.46%\n",
      "\n",
      "Epoch 29/100\n",
      "train loss: 0.0547 | test acc: 98.32%\n",
      "test loss:  0.6848 | test acc:  86.76%\n",
      "\n",
      "Epoch 30/100\n",
      "train loss: 0.0105 | test acc: 99.73%\n",
      "test loss:  0.7360 | test acc:  87.09%\n",
      "\n",
      "Epoch 31/100\n",
      "train loss: 0.0327 | test acc: 98.91%\n",
      "test loss:  0.8102 | test acc:  85.61%\n",
      "\n",
      "Epoch 32/100\n",
      "train loss: 0.0255 | test acc: 99.19%\n",
      "test loss:  0.7247 | test acc:  86.85%\n",
      "\n",
      "Epoch 33/100\n",
      "train loss: 0.0188 | test acc: 99.39%\n",
      "test loss:  0.7562 | test acc:  86.78%\n",
      "\n",
      "Epoch 34/100\n",
      "train loss: 0.0405 | test acc: 98.75%\n",
      "test loss:  0.6927 | test acc:  86.17%\n",
      "\n",
      "Epoch 35/100\n",
      "train loss: 0.0289 | test acc: 99.07%\n",
      "test loss:  0.7391 | test acc:  86.50%\n",
      "\n",
      "Epoch 36/100\n",
      "train loss: 0.0276 | test acc: 99.14%\n",
      "test loss:  0.8376 | test acc:  86.02%\n",
      "\n",
      "Epoch 37/100\n",
      "train loss: 0.0295 | test acc: 99.01%\n",
      "test loss:  0.8581 | test acc:  85.43%\n",
      "\n",
      "Epoch 38/100\n",
      "train loss: 0.0255 | test acc: 99.14%\n",
      "test loss:  0.7761 | test acc:  86.59%\n",
      "\n",
      "Epoch 39/100\n",
      "train loss: 0.0133 | test acc: 99.58%\n",
      "test loss:  0.8315 | test acc:  86.31%\n",
      "\n",
      "Epoch 40/100\n",
      "train loss: 0.0384 | test acc: 98.80%\n",
      "test loss:  0.7834 | test acc:  86.83%\n",
      "checkpoint saved: checkpoints/train_1_20251119_103843/model_epoch_40.pt\n",
      "\n",
      "Epoch 41/100\n",
      "train loss: 0.0090 | test acc: 99.75%\n",
      "test loss:  0.8397 | test acc:  86.96%\n",
      "\n",
      "Epoch 42/100\n",
      "train loss: 0.0118 | test acc: 99.62%\n",
      "test loss:  0.8933 | test acc:  86.30%\n",
      "\n",
      "Epoch 43/100\n",
      "train loss: 0.0525 | test acc: 98.24%\n",
      "test loss:  0.7789 | test acc:  85.76%\n",
      "\n",
      "Epoch 44/100\n",
      "train loss: 0.0156 | test acc: 99.55%\n",
      "test loss:  0.9603 | test acc:  84.48%\n",
      "\n",
      "Epoch 45/100\n",
      "train loss: 0.0139 | test acc: 99.52%\n",
      "test loss:  0.8332 | test acc:  86.85%\n",
      "\n",
      "Epoch 46/100\n",
      "train loss: 0.0102 | test acc: 99.70%\n",
      "test loss:  0.8949 | test acc:  87.04%\n",
      "\n",
      "Epoch 47/100\n",
      "train loss: 0.0296 | test acc: 99.06%\n",
      "test loss:  1.0522 | test acc:  83.72%\n",
      "\n",
      "Epoch 48/100\n",
      "train loss: 0.0350 | test acc: 98.81%\n",
      "test loss:  0.9058 | test acc:  84.72%\n",
      "\n",
      "Epoch 49/100\n",
      "train loss: 0.0211 | test acc: 99.30%\n",
      "test loss:  0.8901 | test acc:  86.87%\n",
      "\n",
      "Epoch 50/100\n",
      "train loss: 0.0223 | test acc: 99.29%\n",
      "test loss:  0.9675 | test acc:  84.89%\n",
      "\n",
      "Epoch 51/100\n",
      "train loss: 0.0158 | test acc: 99.49%\n",
      "test loss:  0.8935 | test acc:  86.41%\n",
      "\n",
      "Epoch 52/100\n",
      "train loss: 0.0065 | test acc: 99.79%\n",
      "test loss:  0.9294 | test acc:  86.52%\n",
      "\n",
      "Epoch 53/100\n",
      "train loss: 0.0195 | test acc: 99.35%\n",
      "test loss:  0.9484 | test acc:  86.13%\n",
      "\n",
      "Epoch 54/100\n",
      "train loss: 0.0191 | test acc: 99.44%\n",
      "test loss:  1.0294 | test acc:  84.78%\n",
      "\n",
      "Epoch 55/100\n",
      "train loss: 0.0184 | test acc: 99.38%\n",
      "test loss:  0.9253 | test acc:  86.91%\n",
      "\n",
      "Epoch 56/100\n",
      "train loss: 0.0037 | test acc: 99.89%\n",
      "test loss:  0.8976 | test acc:  87.69%\n",
      "\n",
      "Epoch 57/100\n",
      "train loss: 0.0030 | test acc: 99.90%\n",
      "test loss:  0.9574 | test acc:  87.39%\n",
      "\n",
      "Epoch 58/100\n",
      "train loss: 0.0007 | test acc: 99.99%\n",
      "test loss:  0.9389 | test acc:  88.02%\n",
      "\n",
      "Epoch 59/100\n",
      "train loss: 0.0002 | test acc: 100.00%\n",
      "test loss:  0.9592 | test acc:  88.07%\n",
      "\n",
      "Epoch 60/100\n",
      "train loss: 0.0001 | test acc: 100.00%\n",
      "test loss:  0.9591 | test acc:  88.11%\n",
      "checkpoint saved: checkpoints/train_1_20251119_103843/model_epoch_60.pt\n",
      "\n",
      "Epoch 61/100\n",
      "train loss: 0.0001 | test acc: 100.00%\n",
      "test loss:  0.9715 | test acc:  88.00%\n",
      "\n",
      "Epoch 62/100\n",
      "train loss: 0.0001 | test acc: 100.00%\n",
      "test loss:  0.9770 | test acc:  88.04%\n",
      "\n",
      "Epoch 63/100\n",
      "train loss: 0.0882 | test acc: 97.35%\n",
      "test loss:  0.7914 | test acc:  85.13%\n",
      "\n",
      "Epoch 64/100\n",
      "train loss: 0.0245 | test acc: 99.25%\n",
      "test loss:  0.8237 | test acc:  86.30%\n",
      "\n",
      "Epoch 65/100\n",
      "train loss: 0.0071 | test acc: 99.77%\n",
      "test loss:  0.8606 | test acc:  86.98%\n",
      "\n",
      "Epoch 66/100\n",
      "train loss: 0.0018 | test acc: 99.98%\n",
      "test loss:  0.9156 | test acc:  87.19%\n",
      "\n",
      "Epoch 67/100\n",
      "train loss: 0.0002 | test acc: 100.00%\n",
      "test loss:  0.8992 | test acc:  87.69%\n",
      "\n",
      "Epoch 68/100\n",
      "train loss: 0.0001 | test acc: 100.00%\n",
      "test loss:  0.9161 | test acc:  87.91%\n",
      "\n",
      "Epoch 69/100\n",
      "train loss: 0.0001 | test acc: 100.00%\n",
      "test loss:  0.9273 | test acc:  87.91%\n",
      "\n",
      "Epoch 70/100\n",
      "train loss: 0.0001 | test acc: 100.00%\n",
      "test loss:  0.9367 | test acc:  87.87%\n",
      "\n",
      "Epoch 71/100\n",
      "train loss: 0.0001 | test acc: 100.00%\n",
      "test loss:  0.9492 | test acc:  87.98%\n",
      "\n",
      "Epoch 72/100\n",
      "train loss: 0.0001 | test acc: 100.00%\n",
      "test loss:  0.9622 | test acc:  87.93%\n",
      "\n",
      "Epoch 73/100\n",
      "train loss: 0.0813 | test acc: 97.76%\n",
      "test loss:  0.7276 | test acc:  85.54%\n",
      "\n",
      "Epoch 74/100\n",
      "train loss: 0.0170 | test acc: 99.50%\n",
      "test loss:  0.9408 | test acc:  85.61%\n",
      "\n",
      "Epoch 75/100\n",
      "train loss: 0.0119 | test acc: 99.64%\n",
      "test loss:  0.9612 | test acc:  85.11%\n",
      "\n",
      "Epoch 76/100\n",
      "train loss: 0.0037 | test acc: 99.90%\n",
      "test loss:  0.8963 | test acc:  87.91%\n",
      "\n",
      "Epoch 77/100\n",
      "train loss: 0.0227 | test acc: 99.24%\n",
      "test loss:  0.9268 | test acc:  85.31%\n",
      "\n",
      "Epoch 78/100\n",
      "train loss: 0.0152 | test acc: 99.49%\n",
      "test loss:  0.8557 | test acc:  87.50%\n",
      "\n",
      "Epoch 79/100\n",
      "train loss: 0.0054 | test acc: 99.81%\n",
      "test loss:  0.9688 | test acc:  86.80%\n",
      "\n",
      "Epoch 80/100\n",
      "train loss: 0.0052 | test acc: 99.82%\n",
      "test loss:  1.0286 | test acc:  86.07%\n",
      "checkpoint saved: checkpoints/train_1_20251119_103843/model_epoch_80.pt\n",
      "\n",
      "Epoch 81/100\n",
      "train loss: 0.0065 | test acc: 99.75%\n",
      "test loss:  1.0018 | test acc:  86.87%\n",
      "\n",
      "Epoch 82/100\n",
      "train loss: 0.0075 | test acc: 99.78%\n",
      "test loss:  1.0663 | test acc:  86.41%\n",
      "\n",
      "Epoch 83/100\n",
      "train loss: 0.0466 | test acc: 98.62%\n",
      "test loss:  1.1908 | test acc:  82.61%\n",
      "\n",
      "Epoch 84/100\n",
      "train loss: 0.0193 | test acc: 99.39%\n",
      "test loss:  0.9247 | test acc:  86.19%\n",
      "\n",
      "Epoch 85/100\n",
      "train loss: 0.0054 | test acc: 99.82%\n",
      "test loss:  1.0003 | test acc:  86.76%\n",
      "\n",
      "Epoch 86/100\n",
      "train loss: 0.0004 | test acc: 100.00%\n",
      "test loss:  0.9532 | test acc:  87.33%\n",
      "\n",
      "Epoch 87/100\n",
      "train loss: 0.0001 | test acc: 100.00%\n",
      "test loss:  0.9714 | test acc:  87.63%\n",
      "\n",
      "Epoch 88/100\n",
      "train loss: 0.0001 | test acc: 100.00%\n",
      "test loss:  0.9825 | test acc:  87.74%\n",
      "\n",
      "Epoch 89/100\n",
      "train loss: 0.0001 | test acc: 100.00%\n",
      "test loss:  0.9928 | test acc:  87.81%\n",
      "\n",
      "Epoch 90/100\n",
      "train loss: 0.0000 | test acc: 100.00%\n",
      "test loss:  0.9995 | test acc:  87.81%\n",
      "\n",
      "Epoch 91/100\n",
      "train loss: 0.0000 | test acc: 100.00%\n",
      "test loss:  1.0075 | test acc:  87.72%\n",
      "\n",
      "Epoch 92/100\n",
      "train loss: 0.0000 | test acc: 100.00%\n",
      "test loss:  1.0159 | test acc:  87.80%\n",
      "\n",
      "Epoch 93/100\n",
      "train loss: 0.0000 | test acc: 100.00%\n",
      "test loss:  1.0217 | test acc:  87.70%\n",
      "\n",
      "Epoch 94/100\n",
      "train loss: 0.0000 | test acc: 100.00%\n",
      "test loss:  1.0339 | test acc:  87.85%\n",
      "\n",
      "Epoch 95/100\n",
      "train loss: 0.0000 | test acc: 100.00%\n",
      "test loss:  1.0377 | test acc:  87.78%\n",
      "\n",
      "Epoch 96/100\n",
      "train loss: 0.0000 | test acc: 100.00%\n",
      "test loss:  1.0455 | test acc:  87.78%\n",
      "\n",
      "Epoch 97/100\n",
      "train loss: 0.0000 | test acc: 100.00%\n",
      "test loss:  1.0503 | test acc:  87.76%\n",
      "\n",
      "Epoch 98/100\n",
      "train loss: 0.0000 | test acc: 100.00%\n",
      "test loss:  1.0579 | test acc:  87.87%\n",
      "\n",
      "Epoch 99/100\n",
      "train loss: 0.0000 | test acc: 100.00%\n",
      "test loss:  1.0647 | test acc:  87.83%\n",
      "\n",
      "Epoch 100/100\n",
      "train loss: 0.0000 | test acc: 100.00%\n",
      "test loss:  1.0718 | test acc:  87.80%\n",
      "checkpoint saved: checkpoints/train_1_20251119_103843/model_epoch_100.pt\n",
      "\n",
      "final checkpoint saved: checkpoints/train_1_20251119_103843/model_final.pt\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "# tensorboard setup\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/train_1_{}'.format(timestamp))\n",
    "\n",
    "checkpoint_dir = f'checkpoints/train_1_{timestamp}'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "    \n",
    "\n",
    "\n",
    "    train_loss, train_acc = train_one_epoch()\n",
    "    \n",
    "    test_loss, test_acc = test_one_epoch()\n",
    "    \n",
    "    print(f'train loss: {train_loss:.4f} | test acc: {train_acc:.2f}%')\n",
    "    print(f'test loss:  {test_loss:.4f} | test acc:  {test_acc:.2f}%')\n",
    "    \n",
    "    # log data\n",
    "    writer.add_scalar('loss/1_train', train_loss, epoch + 1)\n",
    "    writer.add_scalar('loss/2_test', test_loss, epoch + 1)\n",
    "    writer.add_scalar('accuracy/1_train', train_acc, epoch + 1)\n",
    "    writer.add_scalar('accuracy/2_test', test_acc, epoch + 1)\n",
    "    writer.flush()\n",
    "    \n",
    "    # checkpoint every 20 epochs\n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'model_epoch_{epoch + 1}.pt')\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "        print(f'checkpoint saved: {checkpoint_path}')\n",
    "    \n",
    "    print()\n",
    "\n",
    "# save final model\n",
    "final_checkpoint_path = os.path.join(checkpoint_dir, f'model_final.pt')\n",
    "torch.save(model.state_dict(), final_checkpoint_path)\n",
    "print(f'final checkpoint saved: {final_checkpoint_path}')\n",
    "\n",
    "writer.close()\n",
    "print('Complete')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
